"""
ç°ä»£è‰ºæœ¯é£æ ¼ç³»ç»Ÿ

æ”¯æŒé£æ ¼ï¼š
1. ç«‹ä½“ä¸»ä¹‰ (Cubism) - æ¯•åŠ ç´¢ã€å¸ƒæ‹‰å…‹
2. æœªæ¥ä¸»ä¹‰ (Futurism) - æœå°šã€æ³¢ä¸˜å°¼  
3. æ³¢æ™®è‰ºæœ¯ (Pop Art) - æ²ƒéœå°”ã€åˆ©å¸Œæ»•æ–¯å¦
4. é‡å…½æ´¾ (Fauvism) - é©¬è’‚æ–¯
5. è¡¨ç°ä¸»ä¹‰ (Expressionism) - è’™å…‹
6. æŠ½è±¡è¡¨ç°ä¸»ä¹‰ (Abstract Expressionism) - æ³¢æ´›å…‹

å½“å‰ä¸“æ³¨ï¼šç«‹ä½“ä¸»ä¹‰

python modern_art_styles.py
"""

import torch
import gc
from diffusers import (
    ControlNetModel,
    StableDiffusionXLControlNetImg2ImgPipeline,
    StableDiffusionXLImg2ImgPipeline,
)
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import numpy as np
from scipy.spatial import Delaunay
from pathlib import Path
from datetime import datetime
import svgwrite
import json
from abc import ABC, abstractmethod


class ArtStyle(ABC):
    """è‰ºæœ¯é£æ ¼åŸºç±»"""
    
    def __init__(self, name: str):
        self.name = name
        self.device = "mps" if torch.backends.mps.is_available() else "cpu"
    
    @abstractmethod
    def get_prompt(self) -> tuple:
        """è¿”å› (positive_prompt, negative_prompt)"""
        pass
    
    @abstractmethod
    def get_palette(self) -> list:
        """è¿”å›è¯¥é£æ ¼çš„è°ƒè‰²æ¿"""
        pass
    
    @abstractmethod
    def post_process(self, image: np.ndarray) -> np.ndarray:
        """é£æ ¼ç‰¹å®šçš„åå¤„ç†"""
        pass


class CubismStyle(ArtStyle):
    """
    ç«‹ä½“ä¸»ä¹‰é£æ ¼
    
    æ ¸å¿ƒæŠ€æ³•ï¼š
    1. å¤šè§†è§’ç¢ç‰‡ - å°†ç‰©ä½“åˆ†è§£ï¼Œä»å¤šè§’åº¦é‡ç»„
    2. å‡ ä½•ç®€åŒ– - æ‰€æœ‰å½¢ä½“å½’çº³ä¸ºå‡ ä½•ä½“
    3. å¹³é¢äº¤ç»‡ - å‰æ™¯èƒŒæ™¯ç©¿é€
    4. åˆ†ææœŸè‰²è°ƒ - ç°è¤å•è‰²
    5. é”åˆ©è¾¹ç¼˜ - æ˜ç¡®çš„å¹³é¢åˆ†ç•Œ
    """
    
    # åˆ†æç«‹ä½“ä¸»ä¹‰è‰²æ¿ï¼ˆæ¯•åŠ ç´¢/å¸ƒæ‹‰å…‹ 1908-1912ï¼‰
    ANALYTICAL_PALETTE = [
        (89, 78, 65),     # æ·±è¤ç°
        (112, 98, 82),    # ä¸­è¤ç°
        (135, 120, 100),  # æµ…è¤ç°
        (156, 142, 122),  # æš–ç°
        (68, 60, 50),     # æ·±å½±
        (178, 165, 145),  # é«˜å…‰ç°
        (100, 88, 72),    # æ©„æ¦„è¤
        (145, 132, 115),  # ç±³ç°
        (55, 48, 40),     # æœ€æ·±
        (190, 178, 160),  # æœ€äº®
    ]
    
    # ç»¼åˆç«‹ä½“ä¸»ä¹‰è‰²æ¿ï¼ˆ1912-1920ï¼‰
    SYNTHETIC_PALETTE = [
        (45, 65, 95),     # æ·±è“
        (180, 75, 55),    # èµ­çº¢
        (85, 120, 80),    # æ©„æ¦„ç»¿
        (200, 170, 120),  # ç±³é»„
        (60, 50, 45),     # æ·±è¤
        (150, 140, 125),  # ä¸­æ€§ç°
        (120, 90, 60),    # åœŸé»„
        (170, 160, 150),  # æµ…ç°
        (100, 50, 40),    # æ·±çº¢è¤
        (210, 195, 170),  # è±¡ç‰™ç™½
    ]
    
    def __init__(self, sub_style: str = "analytical"):
        """
        sub_style: "analytical" åˆ†æç«‹ä½“ä¸»ä¹‰ / "synthetic" ç»¼åˆç«‹ä½“ä¸»ä¹‰
        """
        super().__init__("Cubism")
        self.sub_style = sub_style
    
    def get_prompt(self) -> tuple:
        if self.sub_style == "analytical":
            positive = (
                "analytical cubism masterpiece by Pablo Picasso and Georges Braque, "
                "portrait fragmented into geometric planes, "
                "multiple perspectives shown simultaneously, "
                "face deconstructed with profile and frontal view combined, "
                "overlapping angular planes intersecting shapes, "
                "monochromatic earth tones brown gray ochre palette, "
                "broken planes with spatial ambiguity, "
                "subtle geometric analysis, intellectually deconstructed forms, "
                "oil on canvas texture, museum quality fine art, "
                "revolutionary composition, 1910 Paris avant-garde"
            )
        else:  # synthetic
            positive = (
                "synthetic cubism masterpiece by Pablo Picasso, "
                "bold geometric color blocks, bright vibrant accents, "
                "collage papier colle aesthetic with newspaper elements, "
                "simplified playful shapes, flat overlapping planes, "
                "figure reconstructed through geometric forms, "
                "dynamic balance of abstract composition, "
                "earth tones with bold color harmony, "
                "decorative patterns, modern art revolution, "
                "oil and mixed media on canvas, museum exhibition quality"
            )
        
        negative = (
            "blurry, soft focus, realistic photograph, photorealistic, "
            "3d render, smooth gradients, soft edges, "
            "anime, cartoon, digital art, low quality, "
            "normal perspective, traditional portrait, realistic face"
        )
        
        return positive, negative
    
    def get_palette(self) -> list:
        if self.sub_style == "analytical":
            return self.ANALYTICAL_PALETTE
        return self.SYNTHETIC_PALETTE
    
    def create_cubist_fragmentation(
        self, 
        image: np.ndarray,
        num_fragments: int = 800,
        edge_weight: float = 0.7,
    ) -> np.ndarray:
        """
        ç«‹ä½“ä¸»ä¹‰ç¢ç‰‡åŒ–
        
        æ ¸å¿ƒï¼šåœ¨è¾¹ç¼˜å’Œç»“æ„çº¿ä¸ŠåŠ å¯†å‡ ä½•åˆ†å‰²
        """
        h, w = image.shape[:2]
        
        # å¤šå±‚æ¬¡è¾¹ç¼˜æ£€æµ‹
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges1 = cv2.Canny(gray, 20, 60)   # å¼±è¾¹ç¼˜
        edges2 = cv2.Canny(gray, 60, 150)  # å¼ºè¾¹ç¼˜
        edges = cv2.bitwise_or(edges1, edges2)
        
        # æ·»åŠ ç»“æ„çº¿ï¼ˆåŸºäºæ¢¯åº¦æ–¹å‘ï¼‰
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient_mag = np.sqrt(sobelx**2 + sobely**2)
        gradient_mask = (gradient_mag > np.percentile(gradient_mag, 70)).astype(np.uint8) * 255
        edges = cv2.bitwise_or(edges, gradient_mask)
        
        # é‡‡æ ·ç‚¹
        points = [(0, 0), (w-1, 0), (0, h-1), (w-1, h-1)]  # å››è§’
        
        # è¾¹ç¼˜é‡‡æ ·
        edge_coords = np.column_stack(np.where(edges > 0))
        n_edge = int(num_fragments * edge_weight)
        if len(edge_coords) > 0:
            indices = np.random.choice(len(edge_coords), min(n_edge, len(edge_coords)), replace=False)
            for idx in indices:
                y, x = edge_coords[idx]
                points.append((x, y))
        
        # éšæœºå¡«å……
        n_random = num_fragments - len(points)
        for _ in range(max(0, n_random)):
            points.append((np.random.randint(0, w), np.random.randint(0, h)))
        
        points = np.array(points)
        
        # Delaunayä¸‰è§’å‰–åˆ†
        tri = Delaunay(points)
        
        # ç»˜åˆ¶ç¢ç‰‡
        canvas = np.zeros((h, w, 3), dtype=np.uint8)
        
        for simplex in tri.simplices:
            pts = points[simplex].astype(np.int32)
            
            # è·å–é¢œè‰²
            cx = int(np.mean(pts[:, 0]))
            cy = int(np.mean(pts[:, 1]))
            cx, cy = max(0, min(w-1, cx)), max(0, min(h-1, cy))
            
            r = 2
            region = image[max(0,cy-r):min(h,cy+r+1), max(0,cx-r):min(w,cx+r+1)]
            if region.size > 0:
                color = np.median(region.reshape(-1, 3), axis=0).astype(int)
            else:
                color = image[cy, cx]
            
            cv2.fillPoly(canvas, [pts], tuple(int(c) for c in color))
        
        return canvas
    
    def add_plane_edges(self, image: np.ndarray, thickness: int = 1) -> np.ndarray:
        """æ·»åŠ å¹³é¢åˆ†ç•Œçº¿ï¼ˆç«‹ä½“ä¸»ä¹‰ç‰¹å¾ï¼‰"""
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        # è†¨èƒ€è¾¹ç¼˜
        kernel = np.ones((2, 2), np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=1)
        
        # å åŠ æ·±è‰²è¾¹ç¼˜çº¿
        result = image.copy()
        edge_color = np.array([40, 35, 30])  # æ·±è¤è‰²çº¿æ¡
        result[edges > 0] = result[edges > 0] * 0.3 + edge_color * 0.7
        
        return result.astype(np.uint8)
    
    def map_to_palette(self, image: np.ndarray) -> np.ndarray:
        """æ˜ å°„åˆ°ç«‹ä½“ä¸»ä¹‰è‰²æ¿"""
        palette = np.array(self.get_palette())
        h, w = image.shape[:2]
        
        pixels = image.reshape(-1, 3)
        result = np.zeros_like(pixels)
        
        for i, pixel in enumerate(pixels):
            distances = np.sqrt(np.sum((palette - pixel) ** 2, axis=1))
            result[i] = palette[np.argmin(distances)]
        
        return result.reshape(h, w, 3).astype(np.uint8)
    
    def post_process(self, image: np.ndarray) -> np.ndarray:
        """ç«‹ä½“ä¸»ä¹‰åå¤„ç†"""
        # 1. å‡ ä½•ç¢ç‰‡åŒ–
        fragmented = self.create_cubist_fragmentation(image)
        
        # 2. è‰²æ¿æ˜ å°„ï¼ˆå¯é€‰ï¼‰
        # fragmented = self.map_to_palette(fragmented)
        
        # 3. æ·»åŠ å¹³é¢è¾¹ç¼˜
        result = self.add_plane_edges(fragmented)
        
        # 4. å¢å¼ºå¯¹æ¯”åº¦
        pil_img = Image.fromarray(result)
        enhancer = ImageEnhance.Contrast(pil_img)
        result = np.array(enhancer.enhance(1.15))
        
        return result


class ModernArtGenerator:
    """ç°ä»£è‰ºæœ¯ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.device = "mps" if torch.backends.mps.is_available() else "cpu"
        self.pipe = None
        self.controlnet = None
        self.use_controlnet = False
        self.output_dir = Path("/Volumes/Seagate/SAM3/06_style_art/output")
    
    def _get_next_version(self, style_name: str) -> int:
        """è·å–ä¸‹ä¸€ä¸ªç‰ˆæœ¬å·"""
        style_dir = self.output_dir / style_name.lower()
        style_dir.mkdir(parents=True, exist_ok=True)
        existing = list(style_dir.glob(f"{style_name.lower()}_v*.svg"))
        if not existing:
            return 1
        versions = []
        for f in existing:
            try:
                v = int(f.stem.split('_v')[1])
                versions.append(v)
            except:
                pass
        return max(versions) + 1 if versions else 1
    
    def load_sd(self, use_controlnet: bool = True):
        """åŠ è½½SDXL"""
        if self.pipe is None or (use_controlnet != self.use_controlnet):
            print("ğŸ“¦ åŠ è½½SDXLæ¨¡å‹...")
            dtype = torch.float16 if self.device != "cpu" else torch.float32

            local_sdxl_path = "/Volumes/Seagate/SAM3/models/stable_diffusion/base_models/sdxl-base"
            
            # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            if Path(local_sdxl_path).exists():
                sdxl_id = local_sdxl_path
                print(f"   ä½¿ç”¨æœ¬åœ°SDXL: {sdxl_id}")
            else:
                sdxl_id = "stabilityai/stable-diffusion-xl-base-1.0"
                print(f"   ä¸‹è½½SDXL: {sdxl_id}")

            # æš‚æ—¶ç¦ç”¨ControlNetï¼ˆæœ¬åœ°æ²¡æœ‰ï¼‰
            self.controlnet = None
            self.pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(
                sdxl_id,
                torch_dtype=dtype,
                use_safetensors=True,
                local_files_only=Path(local_sdxl_path).exists(),
            ).to(self.device)
            self.use_controlnet = False

            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    def clear_memory(self):
        gc.collect()
        if torch.backends.mps.is_available():
            torch.mps.empty_cache()

    def extract_canny(self, image: Image.Image, low: int = 30, high: int = 100) -> Image.Image:
        img_array = np.array(image)
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, low, high)
        edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
        return Image.fromarray(edges_rgb)

    def match_colors(self, image: np.ndarray, reference: np.ndarray, strength: float = 1.0) -> np.ndarray:
        if strength <= 0:
            return image

        img_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        ref_bgr = cv2.cvtColor(reference, cv2.COLOR_RGB2BGR)
        img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)
        ref_lab = cv2.cvtColor(ref_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)

        img_mean, img_std = cv2.meanStdDev(img_lab)
        ref_mean, ref_std = cv2.meanStdDev(ref_lab)

        img_mean = img_mean.reshape((1, 1, 3))
        img_std = img_std.reshape((1, 1, 3))
        ref_mean = ref_mean.reshape((1, 1, 3))
        ref_std = ref_std.reshape((1, 1, 3))

        eps = 1e-6
        result_lab = (img_lab - img_mean) * (ref_std / (img_std + eps)) + ref_mean
        result_lab = np.clip(result_lab, 0, 255).astype(np.uint8)

        result_bgr = cv2.cvtColor(result_lab, cv2.COLOR_LAB2BGR)
        result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)

        if strength >= 1:
            return result_rgb

        blended = image.astype(np.float32) * (1 - strength) + result_rgb.astype(np.float32) * strength
        return np.clip(blended, 0, 255).astype(np.uint8)
    
    def stylize_with_sd(
        self,
        image: Image.Image,
        style: ArtStyle,
        strength: float = 0.55,
        seed: int = 42,
        controlnet_scale: float = 0.5,
        guidance_scale: float = 10.0,
        num_inference_steps: int = 40,
        preserve_colors: bool = False,
        color_match_strength: float = 1.0,
    ) -> Image.Image:
        """ç”¨SDè¿›è¡Œé£æ ¼åŒ–"""
        
        # è°ƒæ•´å°ºå¯¸
        w, h = image.size
        new_w = min(1024, (w // 64) * 64)
        scale = new_w / w
        new_h = int(h * scale // 64) * 64
        image = image.resize((new_w, new_h), Image.LANCZOS)
        
        positive, negative = style.get_prompt()
        if preserve_colors:
            positive = f"{positive}, preserve original colors, keep original color palette"
            negative = f"{negative}, sepia, monochrome"

        generator = torch.Generator(device="cpu").manual_seed(seed)

        try:
            if self.use_controlnet:
                canny_image = self.extract_canny(image, low=30, high=100)
                result = self.pipe(
                    prompt=positive,
                    negative_prompt=negative,
                    image=image,
                    control_image=canny_image,
                    strength=strength,
                    guidance_scale=guidance_scale,
                    controlnet_conditioning_scale=controlnet_scale,
                    num_inference_steps=num_inference_steps,
                    generator=generator,
                ).images[0]
            else:
                result = self.pipe(
                    prompt=positive,
                    negative_prompt=negative,
                    image=image,
                    strength=strength,
                    guidance_scale=guidance_scale,
                    num_inference_steps=num_inference_steps,
                    generator=generator,
                ).images[0]

            if preserve_colors:
                result_np = np.array(result)
                ref_np = np.array(image)
                result_np = self.match_colors(result_np, ref_np, strength=color_match_strength)
                result = Image.fromarray(result_np)

            return result
        finally:
            self.clear_memory()
    
    def to_svg(self, image: np.ndarray, num_colors: int = 20) -> str:
        """è½¬æ¢ä¸ºSVG"""
        h, w = image.shape[:2]
        
        # é¢œè‰²é‡åŒ–
        pixels = image.reshape(-1, 3).astype(np.float32)
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)
        _, labels, centers = cv2.kmeans(pixels, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
        centers = centers.astype(np.uint8)
        quantized = centers[labels.flatten()].reshape(image.shape)
        
        dwg = svgwrite.Drawing(size=(w, h))
        
        # èƒŒæ™¯
        bg_color = centers[np.argmax(np.bincount(labels.flatten()))]
        dwg.add(dwg.rect(insert=(0, 0), size=(w, h), 
                        fill=f'rgb({bg_color[0]},{bg_color[1]},{bg_color[2]})'))
        
        for color in centers:
            mask = np.all(quantized == color, axis=2).astype(np.uint8) * 255
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                if len(contour) < 3:
                    continue
                epsilon = 0.002 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                if len(approx) < 3:
                    continue
                points = [(int(p[0][0]), int(p[0][1])) for p in approx]
                fill = f'rgb({color[0]},{color[1]},{color[2]})'
                dwg.add(dwg.polygon(points=points, fill=fill, stroke='none'))
        
        return dwg.tostring()
    
    def generate(
        self,
        image_path: str,
        style: ArtStyle,
        strength: float = 0.55,
        num_colors: int = 24,
        use_sd: bool = True,
        use_controlnet: bool = True,
        controlnet_scale: float = 0.5,
        guidance_scale: float = 10.0,
        num_inference_steps: int = 40,
        preserve_colors: bool = False,
        color_match_strength: float = 1.0,
        seed: int = None,
        use_post_process: bool = True,
    ) -> dict:
        """ç”Ÿæˆè‰ºæœ¯åŒ–SVG"""
        
        version = self._get_next_version(style.name)
        style_dir = self.output_dir / style.name.lower()
        
        print(f"ğŸ¨ {style.name} v{version}")
        print(f"{'=' * 50}")
        print(f"ğŸ“· è¾“å…¥: {image_path}")
        print(f"   å­é£æ ¼: {getattr(style, 'sub_style', 'default')}")
        print(f"   SDå¼ºåº¦: {strength}")
        print(f"   SVGé¢œè‰²: {num_colors}")
        print(f"   preserve_colors: {preserve_colors}")
        
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert("RGB")
        
        # 1. SDé£æ ¼åŒ–
        if use_sd:
            if seed is None:
                seed = int(np.random.randint(1, 2147483647))
            self.load_sd(use_controlnet=use_controlnet)
            print("\nğŸ¨ SDé£æ ¼åŒ–...")
            styled = self.stylize_with_sd(
                image,
                style,
                strength,
                seed=seed,
                controlnet_scale=controlnet_scale,
                guidance_scale=guidance_scale,
                num_inference_steps=num_inference_steps,
                preserve_colors=preserve_colors,
                color_match_strength=color_match_strength,
            )
            result_array = np.array(styled)
        else:
            result_array = np.array(image)
        
        # 2. é£æ ¼åå¤„ç†
        if use_post_process:
            print("ğŸ“ é£æ ¼åå¤„ç†...")
            result_array = style.post_process(result_array)

        if preserve_colors:
            ref = np.array(image.resize((result_array.shape[1], result_array.shape[0]), Image.LANCZOS))
            result_array = self.match_colors(result_array, ref, strength=color_match_strength)
        
        # 3. SVGçŸ¢é‡åŒ–
        print("ğŸ“ SVGçŸ¢é‡åŒ–...")
        svg_content = self.to_svg(result_array, num_colors)
        
        # ä¿å­˜
        svg_path = style_dir / f"{style.name.lower()}_v{version}.svg"
        with open(svg_path, 'w') as f:
            f.write(svg_content)
        svg_size = svg_path.stat().st_size / 1024
        print(f"âœ… SVG: {svg_path} ({svg_size:.1f} KB)")
        
        # ä¿å­˜é¢„è§ˆPNG
        png_path = style_dir / f"{style.name.lower()}_v{version}_preview.png"
        Image.fromarray(result_array).save(str(png_path))
        
        # ä¿å­˜å‚æ•°
        params = {
            "version": version,
            "style": style.name,
            "sub_style": getattr(style, 'sub_style', 'default'),
            "strength": strength,
            "num_colors": num_colors,
            "use_sd": use_sd,
            "use_controlnet": use_controlnet,
            "controlnet_scale": controlnet_scale,
            "guidance_scale": guidance_scale,
            "num_inference_steps": num_inference_steps,
            "preserve_colors": preserve_colors,
            "color_match_strength": color_match_strength,
            "seed": seed,
            "use_post_process": use_post_process,
        }
        params_path = style_dir / f"{style.name.lower()}_v{version}_params.json"
        with open(params_path, 'w') as f:
            json.dump(params, f, indent=2)
        
        return {
            'svg_path': str(svg_path),
            'png_path': str(png_path),
            'version': version,
        }


def main():
    input_image = "/Volumes/Seagate/SAM3/01_input/Ladygaga_2.jpg"
    
    if not Path(input_image).exists():
        print(f"âŒ æ‰¾ä¸åˆ°: {input_image}")
        return
    
    print("=" * 60)
    print("ğŸ¨ ç°ä»£è‰ºæœ¯é£æ ¼ç³»ç»Ÿ - ç«‹ä½“ä¸»ä¹‰")
    print("=" * 60)
    
    # åˆ›å»ºç«‹ä½“ä¸»ä¹‰é£æ ¼
    cubism = CubismStyle(sub_style="synthetic")  # analytical / synthetic
    
    # ç”Ÿæˆå™¨
    generator = ModernArtGenerator()
    
    result = generator.generate(
        input_image,
        style=cubism,
        strength=0.55,
        num_colors=96,
        use_sd=True,
        use_controlnet=True,
        controlnet_scale=0.6,
        guidance_scale=8.0,
        num_inference_steps=30,
        preserve_colors=True,
        color_match_strength=1.0,
        use_post_process=True,
    )
    
    print("\n" + "=" * 60)
    print(f"âœ… å®Œæˆï¼ç«‹ä½“ä¸»ä¹‰ v{result['version']}")
    print("=" * 60)
    
    import subprocess
    subprocess.run(["open", result['svg_path']])


if __name__ == "__main__":
    main()
