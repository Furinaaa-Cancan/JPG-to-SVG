#!/usr/bin/env python3
"""
ç§‘ç ”ç»˜å›¾çŸ¢é‡åŒ–å¤„ç†å™¨ v3
æ ¸å¿ƒæ”¹è¿›ï¼š
1. è§£å†³æ–‡å­—ä¸é¢œè‰²é‡å é—®é¢˜
2. SAM3å¤„ç†3Dæ‚¬è‡‚æ¢å¤æ‚åŒºåŸŸ
3. ç”Ÿæˆé«˜è´¨é‡åˆ†å±‚Mask
"""

import sys
import cv2
import numpy as np
from PIL import Image
from pathlib import Path
from datetime import datetime
import json

# æ·»åŠ SAM3è·¯å¾„
sys.path.insert(0, "/Volumes/Seagate/SAM3")
sys.path.insert(0, "/Volumes/Seagate/SAM3/models/sam3")


class ScientificFigureV3:
    """ç§‘ç ”å›¾å¤„ç†å™¨ v3 - é«˜è´¨é‡Mask"""
    
    def __init__(self):
        self.ocr = None
        self.sam3_processor = None
        self.sam3_model = None
        
    def _init_ocr(self):
        """å»¶è¿ŸåŠ è½½OCR"""
        if self.ocr is None:
            try:
                import easyocr
                print("ğŸ”¤ åŠ è½½EasyOCR...")
                self.ocr = easyocr.Reader(['en'], gpu=False, verbose=False)
                print("âœ… EasyOCRåŠ è½½æˆåŠŸ")
            except ImportError:
                print("âš ï¸ EasyOCRæœªå®‰è£…")
                self.ocr = "fallback"
    
    def _init_sam3(self):
        """å»¶è¿ŸåŠ è½½SAM3"""
        if self.sam3_processor is None:
            try:
                from sam3.model_builder import build_sam3_image_model
                from sam3.model.sam3_image_processor import Sam3Processor
                
                print("ğŸ§  åŠ è½½SAM3...")
                self.sam3_model = build_sam3_image_model(device="cpu")
                self.sam3_processor = Sam3Processor(self.sam3_model, device="cpu")
                print("âœ… SAM3åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ SAM3åŠ è½½å¤±è´¥: {e}")
                self.sam3_processor = "fallback"
    
    def detect_text_precise(self, image_path: str) -> tuple:
        """ç²¾ç¡®æ–‡å­—æ£€æµ‹ï¼Œè¿”å›(text_regions, text_mask)"""
        print("\n" + "="*60)
        print("ğŸ“ STEP 1: ç²¾ç¡®æ–‡å­—æ£€æµ‹")
        print("="*60)
        
        img = cv2.imread(image_path)
        h, w = img.shape[:2]
        text_mask = np.zeros((h, w), dtype=np.uint8)
        text_regions = []
        
        self._init_ocr()
        
        if self.ocr != "fallback":
            results = self.ocr.readtext(image_path)
            
            for (bbox, text, conf) in results:
                if conf < 0.3:
                    continue
                
                pts = np.array(bbox, dtype=np.int32)
                x, y, bw, bh = cv2.boundingRect(pts)
                
                # ç²¾ç¡®å¤šè¾¹å½¢maskè€ŒéçŸ©å½¢
                cv2.fillPoly(text_mask, [pts], 255)
                
                text_regions.append({
                    "bbox": [x, y, bw, bh],
                    "text": text,
                    "confidence": conf,
                    "polygon": pts.tolist()
                })
            
            print(f"   æ£€æµ‹åˆ° {len(text_regions)} ä¸ªæ–‡å­—åŒºåŸŸ")
        
        # è½»å¾®è†¨èƒ€ç¡®ä¿å®Œå…¨è¦†ç›–
        kernel = np.ones((3, 3), np.uint8)
        text_mask = cv2.dilate(text_mask, kernel, iterations=1)
        
        coverage = np.sum(text_mask > 0) / (w * h)
        print(f"   æ–‡å­—maskè¦†ç›–ç‡: {coverage:.1%}")
        
        return text_regions, text_mask
    
    def separate_colors_clean(self, image_path: str, text_mask: np.ndarray) -> dict:
        """
        é¢œè‰²åˆ†ç¦» - å…³é”®æ”¹è¿›ï¼šä»é¢œè‰²maskä¸­æ’é™¤æ–‡å­—åŒºåŸŸ
        """
        print("\n" + "="*60)
        print("ğŸ¨ STEP 2: é¢œè‰²åˆ†ç¦»ï¼ˆæ’é™¤æ–‡å­—ï¼‰")
        print("="*60)
        
        img = cv2.imread(image_path)
        img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        h, w = img.shape[:2]
        
        # åˆ›å»ºéæ–‡å­—åŒºåŸŸmask
        non_text_mask = ~text_mask.astype(bool)
        
        layers = {}
        
        # çº¢è‰²æ£€æµ‹
        red_lower1 = np.array([0, 70, 50])
        red_upper1 = np.array([10, 255, 255])
        red_lower2 = np.array([170, 70, 50])
        red_upper2 = np.array([180, 255, 255])
        red_raw = cv2.inRange(img_hsv, red_lower1, red_upper1) | cv2.inRange(img_hsv, red_lower2, red_upper2)
        # æ’é™¤æ–‡å­—åŒºåŸŸ
        layers["red"] = (red_raw & (non_text_mask * 255).astype(np.uint8))
        
        # è“è‰²æ£€æµ‹
        blue_lower = np.array([100, 70, 50])
        blue_upper = np.array([130, 255, 255])
        blue_raw = cv2.inRange(img_hsv, blue_lower, blue_upper)
        layers["blue"] = (blue_raw & (non_text_mask * 255).astype(np.uint8))
        
        # é»‘è‰²æ£€æµ‹
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, black_raw = cv2.threshold(gray, 80, 255, cv2.THRESH_BINARY_INV)
        # æ’é™¤æ–‡å­—å’Œå·²è¯†åˆ«çš„çº¢è“
        black_clean = black_raw & (non_text_mask * 255).astype(np.uint8)
        black_clean = black_clean & ~layers["red"] & ~layers["blue"]
        layers["black"] = black_clean
        
        # æ‰“å°ç»Ÿè®¡
        total = w * h
        for name, mask in layers.items():
            pct = np.sum(mask > 0) / total * 100
            print(f"   {name}: {pct:.2f}%")
        
        return layers
    
    def segment_3d_beam_with_sam3(self, image_path: str, text_mask: np.ndarray) -> dict:
        """
        ä½¿ç”¨SAM3åˆ†å‰²3Dæ‚¬è‡‚æ¢åŒºåŸŸ
        """
        print("\n" + "="*60)
        print("ğŸ§  STEP 3: SAM3åˆ†å‰²3Dæ‚¬è‡‚æ¢")
        print("="*60)
        
        self._init_sam3()
        
        if self.sam3_processor == "fallback":
            print("   è·³è¿‡SAM3ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self._segment_beam_fallback(image_path)
        
        img = Image.open(image_path)
        img_array = np.array(img)
        h, w = img_array.shape[:2]
        
        # è®¾ç½®å›¾åƒ
        state = self.sam3_processor.set_image(img)
        
        # é’ˆå¯¹3Dæ‚¬è‡‚æ¢çš„prompt
        beam_prompts = [
            "3D cantilever beam",
            "mechanical beam structure", 
            "strain gauge mounting plate",
            "metal beam with strain gauges"
        ]
        
        beam_masks = []
        
        for prompt in beam_prompts:
            print(f"   å°è¯•: '{prompt}'")
            try:
                state = self.sam3_processor.set_text_prompt(prompt, state)
                
                if state and "masks" in state and len(state["masks"]) > 0:
                    for mask in state["masks"]:
                        mask_array = np.array(mask)
                        
                        # å¤„ç†å¤šç»´mask (squeezeæ‰batchç»´åº¦)
                        while mask_array.ndim > 2:
                            mask_array = mask_array.squeeze(0)
                        
                        if mask_array.dtype == bool:
                            mask_array = mask_array.astype(np.uint8) * 255
                        elif mask_array.max() <= 1:
                            mask_array = (mask_array * 255).astype(np.uint8)
                        
                        area = np.sum(mask_array > 0)
                        if area > 1000:  # è¿‡æ»¤å¤ªå°çš„
                            beam_masks.append({
                                "prompt": prompt,
                                "mask": mask_array,
                                "area": int(area)
                            })
                            print(f"      âœ“ æ‰¾åˆ°mask, é¢ç§¯: {area}")
            except Exception as e:
                print(f"      âœ— å¤±è´¥: {e}")
        
        if not beam_masks:
            print("   SAM3æœªæ‰¾åˆ°æ‚¬è‡‚æ¢ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self._segment_beam_fallback(image_path)
        
        # é€‰æ‹©æœ€ä½³maskï¼ˆé¢ç§¯æœ€å¤§çš„ï¼‰
        best_mask = max(beam_masks, key=lambda x: x["area"])
        print(f"\n   âœ… é€‰æ‹©æœ€ä½³mask: '{best_mask['prompt']}', é¢ç§¯: {best_mask['area']}")
        
        return {
            "beam_3d": best_mask["mask"],
            "method": "sam3",
            "prompt": best_mask["prompt"]
        }
    
    def _segment_beam_fallback(self, image_path: str) -> dict:
        """å¤‡ç”¨æ–¹æ³•ï¼šåŸºäºä½ç½®å’Œé¢œè‰²åˆ†å‰²æ‚¬è‡‚æ¢"""
        print("   ä½¿ç”¨ä½ç½®+é¢œè‰²å¤‡ç”¨æ–¹æ³•")
        
        img = cv2.imread(image_path)
        h, w = img.shape[:2]
        
        # æ‚¬è‡‚æ¢å¤§çº¦åœ¨å›¾åƒå·¦ä¾§1/3åŒºåŸŸ
        beam_region = np.zeros((h, w), dtype=np.uint8)
        
        # åŸºäºç°åº¦å’Œä½ç½®
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # å·¦ä¾§åŒºåŸŸ
        left_region = gray[:, :int(w*0.4)]
        
        # æ‚¬è‡‚æ¢æ˜¯æµ…ç°è‰²å¸¦é˜´å½±
        _, beam_mask = cv2.threshold(left_region, 180, 255, cv2.THRESH_BINARY)
        beam_mask_inv = cv2.bitwise_not(beam_mask)
        
        # å½¢æ€å­¦å¤„ç†
        kernel = np.ones((5, 5), np.uint8)
        beam_mask_clean = cv2.morphologyEx(beam_mask_inv, cv2.MORPH_CLOSE, kernel)
        beam_mask_clean = cv2.morphologyEx(beam_mask_clean, cv2.MORPH_OPEN, kernel)
        
        # æ”¾å›å®Œæ•´å°ºå¯¸
        beam_region[:, :int(w*0.4)] = beam_mask_clean
        
        # æŸ¥æ‰¾æœ€å¤§è¿é€šåŸŸ
        contours, _ = cv2.findContours(beam_region, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            largest = max(contours, key=cv2.contourArea)
            final_mask = np.zeros((h, w), dtype=np.uint8)
            cv2.drawContours(final_mask, [largest], -1, 255, -1)
            
            area = cv2.contourArea(largest)
            print(f"   âœ… å¤‡ç”¨æ–¹æ³•æ‰¾åˆ°æ‚¬è‡‚æ¢, é¢ç§¯: {area}")
            
            return {
                "beam_3d": final_mask,
                "method": "fallback",
                "prompt": "position+color"
            }
        
        return {
            "beam_3d": np.zeros((h, w), dtype=np.uint8),
            "method": "failed",
            "prompt": None
        }
    
    def refine_masks(self, text_mask: np.ndarray, color_layers: dict, 
                     beam_result: dict) -> dict:
        """
        STEP 4: ä¼˜åŒ–å’Œæ•´åˆæ‰€æœ‰mask
        ç¡®ä¿å±‚æ¬¡æ¸…æ™°ï¼Œæ— é‡å 
        """
        print("\n" + "="*60)
        print("ğŸ”§ STEP 4: Maskä¼˜åŒ–ä¸æ•´åˆ")
        print("="*60)
        
        h, w = text_mask.shape
        
        # åˆ›å»ºä¼˜å…ˆçº§å±‚æ¬¡ï¼ˆé«˜ä¼˜å…ˆçº§è¦†ç›–ä½ä¼˜å…ˆçº§ï¼‰
        # ä¼˜å…ˆçº§: æ–‡å­— > çº¢è‰² > è“è‰² > 3Dæ‚¬è‡‚æ¢ > é»‘è‰²çº¿æ¡ > èƒŒæ™¯
        
        final_masks = {
            "L1_text": text_mask.copy(),
            "L2_red": np.zeros((h, w), dtype=np.uint8),
            "L3_blue": np.zeros((h, w), dtype=np.uint8),
            "L4_beam_3d": np.zeros((h, w), dtype=np.uint8),
            "L5_black_lines": np.zeros((h, w), dtype=np.uint8),
            "L6_background": np.zeros((h, w), dtype=np.uint8)
        }
        
        # å·²å ç”¨åŒºåŸŸ
        occupied = text_mask > 0
        
        # L2: çº¢è‰²ï¼ˆæ’é™¤æ–‡å­—ï¼‰
        red_clean = color_layers["red"].copy()
        red_clean[occupied] = 0
        final_masks["L2_red"] = red_clean
        occupied = occupied | (red_clean > 0)
        
        # L3: è“è‰²ï¼ˆæ’é™¤æ–‡å­—å’Œçº¢è‰²ï¼‰
        blue_clean = color_layers["blue"].copy()
        blue_clean[occupied] = 0
        final_masks["L3_blue"] = blue_clean
        occupied = occupied | (blue_clean > 0)
        
        # L4: 3Dæ‚¬è‡‚æ¢ï¼ˆæ’é™¤å·²å ç”¨ï¼‰
        beam_mask = beam_result.get("beam_3d", np.zeros((h, w), dtype=np.uint8))
        beam_clean = beam_mask.copy()
        beam_clean[occupied] = 0
        final_masks["L4_beam_3d"] = beam_clean
        occupied = occupied | (beam_clean > 0)
        
        # L5: é»‘è‰²çº¿æ¡ï¼ˆæ’é™¤å·²å ç”¨ï¼‰
        black_clean = color_layers["black"].copy()
        black_clean[occupied] = 0
        final_masks["L5_black_lines"] = black_clean
        occupied = occupied | (black_clean > 0)
        
        # L6: èƒŒæ™¯ï¼ˆå‰©ä½™åŒºåŸŸï¼‰
        final_masks["L6_background"] = (~occupied).astype(np.uint8) * 255
        
        # æ‰“å°ç»Ÿè®¡
        print("\n   åˆ†å±‚Maskç»Ÿè®¡:")
        total = h * w
        for name, mask in final_masks.items():
            pct = np.sum(mask > 0) / total * 100
            print(f"   - {name}: {pct:.2f}%")
        
        # éªŒè¯æ— é‡å 
        overlap_check = np.zeros((h, w), dtype=np.int32)
        for mask in final_masks.values():
            overlap_check += (mask > 0).astype(np.int32)
        
        max_overlap = np.max(overlap_check)
        if max_overlap > 1:
            print(f"   âš ï¸ è­¦å‘Š: æ£€æµ‹åˆ°é‡å åŒºåŸŸ (æœ€å¤§é‡å å±‚æ•°: {max_overlap})")
        else:
            print("   âœ… éªŒè¯é€šè¿‡: æ— é‡å ")
        
        return final_masks
    
    def create_visualization(self, image_path: str, text_regions: list,
                             final_masks: dict, output_dir: str) -> str:
        """ç”Ÿæˆé«˜è´¨é‡å¯è§†åŒ–"""
        print("\n" + "="*60)
        print("ğŸ“Š STEP 5: ç”Ÿæˆå¯è§†åŒ–")
        print("="*60)
        
        img = cv2.imread(image_path)
        h, w = img.shape[:2]
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # åˆ›å»ºå½©è‰²maskå åŠ å›¾
        vis_overlay = img.copy()
        
        # å®šä¹‰æ¯å±‚é¢œè‰² (BGR)
        layer_colors = {
            "L1_text": (0, 255, 0),        # ç»¿è‰²
            "L2_red": (0, 0, 255),          # çº¢è‰²
            "L3_blue": (255, 0, 0),         # è“è‰²
            "L4_beam_3d": (128, 128, 0),    # é’è‰²
            "L5_black_lines": (128, 128, 128),  # ç°è‰²
        }
        
        for layer_name, color in layer_colors.items():
            mask = final_masks.get(layer_name)
            if mask is not None and np.sum(mask) > 0:
                # åŠé€æ˜å åŠ 
                overlay_region = vis_overlay.copy()
                overlay_region[mask > 0] = color
                vis_overlay = cv2.addWeighted(vis_overlay, 0.7, overlay_region, 0.3, 0)
        
        # åˆ›å»ºåˆ†å±‚å±•ç¤ºå›¾ (2x3ç½‘æ ¼)
        cell_h, cell_w = h, w
        grid = np.ones((cell_h * 2, cell_w * 3, 3), dtype=np.uint8) * 255
        
        # Row 1: åŸå›¾, æ–‡å­—mask, çº¢è‰²mask
        grid[0:cell_h, 0:cell_w] = img
        grid[0:cell_h, cell_w:cell_w*2] = cv2.cvtColor(final_masks["L1_text"], cv2.COLOR_GRAY2BGR)
        grid[0:cell_h, cell_w*2:cell_w*3] = cv2.cvtColor(final_masks["L2_red"], cv2.COLOR_GRAY2BGR)
        
        # Row 2: è“è‰²mask, 3Dæ‚¬è‡‚æ¢mask, å åŠ ç»“æœ
        grid[cell_h:cell_h*2, 0:cell_w] = cv2.cvtColor(final_masks["L3_blue"], cv2.COLOR_GRAY2BGR)
        grid[cell_h:cell_h*2, cell_w:cell_w*2] = cv2.cvtColor(final_masks["L4_beam_3d"], cv2.COLOR_GRAY2BGR)
        grid[cell_h:cell_h*2, cell_w*2:cell_w*3] = vis_overlay
        
        # æ·»åŠ æ ‡ç­¾
        font = cv2.FONT_HERSHEY_SIMPLEX
        labels = [
            ("Original", (10, 20)),
            ("L1: Text", (cell_w + 10, 20)),
            ("L2: Red Elements", (cell_w*2 + 10, 20)),
            ("L3: Blue Elements", (10, cell_h + 20)),
            ("L4: 3D Beam (SAM3)", (cell_w + 10, cell_h + 20)),
            ("Final Overlay", (cell_w*2 + 10, cell_h + 20)),
        ]
        
        for label, pos in labels:
            cv2.putText(grid, label, pos, font, 0.5, (0, 0, 0), 1)
        
        # ä¿å­˜
        grid_path = f"{output_dir}/v3_layers_{timestamp}.png"
        cv2.imwrite(grid_path, grid)
        print(f"   åˆ†å±‚å›¾å·²ä¿å­˜: {grid_path}")
        
        # ä¿å­˜å•ç‹¬çš„é«˜è´¨é‡mask
        for name, mask in final_masks.items():
            mask_path = f"{output_dir}/v3_{name}_{timestamp}.png"
            cv2.imwrite(mask_path, mask)
        print(f"   å„å±‚Maskå·²ä¿å­˜åˆ°: {output_dir}")
        
        # ä¿å­˜å åŠ å›¾
        overlay_path = f"{output_dir}/v3_overlay_{timestamp}.png"
        cv2.imwrite(overlay_path, vis_overlay)
        
        return grid_path
    
    def process(self, image_path: str, output_dir: str = None) -> dict:
        """å®Œæ•´å¤„ç†æµç¨‹"""
        print("\n" + "="*70)
        print("ğŸ¯ ç§‘ç ”ç»˜å›¾çŸ¢é‡åŒ–å¤„ç†å™¨ v3 - é«˜è´¨é‡Mask")
        print("="*70)
        print(f"è¾“å…¥: {image_path}")
        
        if output_dir is None:
            output_dir = "/Volumes/Seagate/SAM3/02_output/scientific_v3"
        
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # Step 1: ç²¾ç¡®æ–‡å­—æ£€æµ‹
        text_regions, text_mask = self.detect_text_precise(image_path)
        
        # Step 2: é¢œè‰²åˆ†ç¦»ï¼ˆæ’é™¤æ–‡å­—ï¼‰
        color_layers = self.separate_colors_clean(image_path, text_mask)
        
        # Step 3: SAM3åˆ†å‰²3Dæ‚¬è‡‚æ¢
        beam_result = self.segment_3d_beam_with_sam3(image_path, text_mask)
        
        # Step 4: ä¼˜åŒ–æ•´åˆ
        final_masks = self.refine_masks(text_mask, color_layers, beam_result)
        
        # Step 5: å¯è§†åŒ–
        vis_path = self.create_visualization(image_path, text_regions, final_masks, output_dir)
        
        result = {
            "text_count": len(text_regions),
            "beam_method": beam_result.get("method"),
            "layers": list(final_masks.keys()),
            "visualization": vis_path
        }
        
        print("\n" + "="*70)
        print("âœ… å¤„ç†å®Œæˆ")
        print("="*70)
        
        return result


def main():
    processor = ScientificFigureV3()
    
    image_path = "/Volumes/Seagate/SAM3/01_input/ç§‘ç ”ç»˜å›¾1.png"
    result = processor.process(image_path)
    
    print("\nğŸ“Š ç»“æœ:")
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()
