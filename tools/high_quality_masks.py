#!/usr/bin/env python3
"""
é«˜è´¨é‡Maskç”Ÿæˆå™¨
ç”Ÿæˆæé«˜ç²¾åº¦çš„åˆ†å±‚maskï¼Œé€‚åˆçŸ¢é‡åŒ–å¤„ç†
"""

import cv2
import numpy as np
from pathlib import Path
from datetime import datetime
import sys

sys.path.insert(0, "/Volumes/Seagate/SAM3")
sys.path.insert(0, "/Volumes/Seagate/SAM3/models/sam3")


class HighQualityMaskGenerator:
    """é«˜è´¨é‡Maskç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = None):
        self.output_dir = output_dir or "/Volumes/Seagate/SAM3/02_output/hq_masks"
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        self.sam3_processor = None
        self.ocr_reader = None
        
    def _init_sam3(self):
        """åˆå§‹åŒ–SAM3"""
        if self.sam3_processor is not None:
            return
        try:
            from sam3.model_builder import build_sam3_image_model
            print("ğŸ§  åŠ è½½SAM3...")
            self.sam3_processor = build_sam3_image_model()
            print("âœ… SAM3åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ SAM3åŠ è½½å¤±è´¥: {e}")
            self.sam3_processor = "fallback"
    
    def _init_ocr(self):
        """åˆå§‹åŒ–OCR"""
        if self.ocr_reader is not None:
            return
        try:
            import easyocr
            print("ğŸ”¤ åŠ è½½EasyOCR...")
            self.ocr_reader = easyocr.Reader(['en'], gpu=False, verbose=False)
            print("âœ… EasyOCRåŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ OCRåŠ è½½å¤±è´¥: {e}")
            self.ocr_reader = "fallback"
    
    def generate_high_quality_masks(self, image_path: str) -> dict:
        """
        ç”Ÿæˆé«˜è´¨é‡åˆ†å±‚mask
        
        è¿”å›ï¼š
        - ç²¾ç¡®çš„è¾¹ç¼˜æ£€æµ‹
        - æŠ—é”¯é½¿å¤„ç†
        - æ— å‹ç¼©PNGè¾“å‡º
        """
        print("\n" + "="*70)
        print("ğŸ¯ é«˜è´¨é‡Maskç”Ÿæˆ")
        print("="*70)
        print(f"   è¾“å…¥: {image_path}")
        
        # è¯»å–å›¾ç‰‡
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        
        h, w = img.shape[:2]
        print(f"   å°ºå¯¸: {w}Ã—{h}")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_subdir = Path(self.output_dir) / f"hq_{timestamp}"
        output_subdir.mkdir(parents=True, exist_ok=True)
        
        results = {
            "image_size": (w, h),
            "output_dir": str(output_subdir),
            "masks": {}
        }
        
        # Step 1: ç²¾ç¡®æ–‡å­—æ£€æµ‹
        print("\n" + "-"*50)
        print("ğŸ“ Step 1: ç²¾ç¡®æ–‡å­—æ£€æµ‹")
        print("-"*50)
        text_mask, text_regions = self._detect_text_precise(img)
        results["text_regions"] = text_regions
        
        # Step 2: ç²¾ç¡®é¢œè‰²åˆ†ç¦»
        print("\n" + "-"*50)
        print("ğŸ¨ Step 2: ç²¾ç¡®é¢œè‰²åˆ†ç¦»")
        print("-"*50)
        color_masks = self._separate_colors_precise(img, text_mask)
        
        # Step 3: SAM3åˆ†å‰²å¤æ‚ç»“æ„
        print("\n" + "-"*50)
        print("ğŸ§  Step 3: SAM3åˆ†å‰²")
        print("-"*50)
        beam_mask = self._segment_with_sam3(image_path, text_mask)
        
        # Step 4: ç²¾ç»†è¾¹ç¼˜å¤„ç†
        print("\n" + "-"*50)
        print("âœ¨ Step 4: è¾¹ç¼˜ç²¾ç»†åŒ–")
        print("-"*50)
        
        # æ•´åˆæ‰€æœ‰maskï¼Œç¡®ä¿æ— é‡å 
        final_masks = self._integrate_masks(
            h, w, text_mask, color_masks, beam_mask
        )
        
        # Step 5: ä¿å­˜é«˜è´¨é‡PNGï¼ˆæ— å‹ç¼©ï¼‰
        print("\n" + "-"*50)
        print("ğŸ’¾ Step 5: ä¿å­˜é«˜è´¨é‡Mask")
        print("-"*50)
        
        for layer_name, mask in final_masks.items():
            # è¾¹ç¼˜æŠ—é”¯é½¿
            mask_aa = self._anti_alias_mask(mask)
            
            # ä¿å­˜ä¸ºæ— å‹ç¼©PNG
            output_path = output_subdir / f"{layer_name}.png"
            cv2.imwrite(str(output_path), mask_aa, 
                       [cv2.IMWRITE_PNG_COMPRESSION, 0])  # 0 = æ— å‹ç¼©
            
            # è®¡ç®—è¦†ç›–ç‡
            coverage = np.sum(mask > 0) / (h * w) * 100
            file_size = output_path.stat().st_size
            
            print(f"   {layer_name}: {coverage:.2f}% ({file_size/1024:.1f}KB)")
            results["masks"][layer_name] = {
                "path": str(output_path),
                "coverage": coverage,
                "size_kb": file_size / 1024
            }
        
        # ä¿å­˜å åŠ é¢„è§ˆ
        self._save_overlay_preview(img, final_masks, output_subdir / "overlay.png")
        
        # ä¿å­˜åŸå›¾å‰¯æœ¬
        cv2.imwrite(str(output_subdir / "original.png"), img,
                   [cv2.IMWRITE_PNG_COMPRESSION, 0])
        
        print("\n" + "="*70)
        print("âœ… é«˜è´¨é‡Maskç”Ÿæˆå®Œæˆ")
        print("="*70)
        print(f"   è¾“å‡ºç›®å½•: {output_subdir}")
        
        return results
    
    def _detect_text_precise(self, img: np.ndarray) -> tuple:
        """ç²¾ç¡®æ–‡å­—æ£€æµ‹"""
        self._init_ocr()
        
        h, w = img.shape[:2]
        text_mask = np.zeros((h, w), dtype=np.uint8)
        text_regions = []
        
        if self.ocr_reader == "fallback":
            print("   ä½¿ç”¨å¤‡ç”¨æ–‡å­—æ£€æµ‹")
            return text_mask, text_regions
        
        # ä½¿ç”¨EasyOCRæ£€æµ‹
        results = self.ocr_reader.readtext(img)
        
        for bbox, text, conf in results:
            if conf < 0.3:
                continue
            
            pts = np.array(bbox, dtype=np.int32)
            
            # ç²¾ç¡®å¡«å……å¤šè¾¹å½¢ï¼ˆæ— è†¨èƒ€ï¼Œä¿æŒåŸå§‹è¾¹ç•Œï¼‰
            cv2.fillPoly(text_mask, [pts], 255)
            
            x_min = int(min(p[0] for p in bbox))
            y_min = int(min(p[1] for p in bbox))
            x_max = int(max(p[0] for p in bbox))
            y_max = int(max(p[1] for p in bbox))
            
            text_regions.append({
                "bbox": [x_min, y_min, x_max - x_min, y_max - y_min],
                "text": text,
                "confidence": conf,
                "polygon": bbox
            })
        
        print(f"   æ£€æµ‹åˆ° {len(text_regions)} ä¸ªæ–‡å­—åŒºåŸŸ")
        coverage = np.sum(text_mask > 0) / (h * w) * 100
        print(f"   æ–‡å­—è¦†ç›–ç‡: {coverage:.2f}%")
        
        return text_mask, text_regions
    
    def _separate_colors_precise(self, img: np.ndarray, 
                                  text_mask: np.ndarray) -> dict:
        """ç²¾ç¡®é¢œè‰²åˆ†ç¦»"""
        h, w = img.shape[:2]
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # æ›´ç²¾ç¡®çš„é¢œè‰²èŒƒå›´
        color_ranges = {
            "red": [
                (np.array([0, 100, 100]), np.array([10, 255, 255])),
                (np.array([160, 100, 100]), np.array([180, 255, 255]))
            ],
            "blue": [
                (np.array([100, 80, 80]), np.array([130, 255, 255]))
            ],
            "black": [
                (np.array([0, 0, 0]), np.array([180, 50, 80]))
            ]
        }
        
        color_masks = {}
        text_mask_inv = cv2.bitwise_not(text_mask)
        
        for color_name, ranges in color_ranges.items():
            mask = np.zeros((h, w), dtype=np.uint8)
            for lower, upper in ranges:
                m = cv2.inRange(hsv, lower, upper)
                mask = cv2.bitwise_or(mask, m)
            
            # æ’é™¤æ–‡å­—åŒºåŸŸ
            mask = cv2.bitwise_and(mask, text_mask_inv)
            
            # ç²¾ç»†å½¢æ€å­¦å¤„ç†ï¼ˆå°kernelä¿ç•™ç»†èŠ‚ï¼‰
            kernel = np.ones((2, 2), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            
            coverage = np.sum(mask > 0) / (h * w) * 100
            print(f"   {color_name}: {coverage:.2f}%")
            
            color_masks[color_name] = mask
        
        return color_masks
    
    def _segment_with_sam3(self, image_path: str, 
                           text_mask: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨SAM3åˆ†å‰²å¤æ‚ç»“æ„"""
        self._init_sam3()
        
        img = cv2.imread(image_path)
        h, w = img.shape[:2]
        
        if self.sam3_processor == "fallback":
            return self._segment_beam_fallback(img)
        
        try:
            from PIL import Image
            pil_img = Image.open(image_path)
            state = self.sam3_processor.set_image(pil_img)
            
            prompts = [
                "3D cantilever beam",
                "mechanical beam structure", 
                "metal beam with strain gauges"
            ]
            
            best_mask = None
            best_area = 0
            
            for prompt in prompts:
                try:
                    state = self.sam3_processor.set_text_prompt(prompt, state)
                    if state and "masks" in state and len(state["masks"]) > 0:
                        for mask in state["masks"]:
                            mask_arr = np.array(mask)
                            while mask_arr.ndim > 2:
                                mask_arr = mask_arr.squeeze(0)
                            
                            if mask_arr.dtype == bool:
                                mask_arr = mask_arr.astype(np.uint8) * 255
                            elif mask_arr.max() <= 1:
                                mask_arr = (mask_arr * 255).astype(np.uint8)
                            
                            area = np.sum(mask_arr > 0)
                            if area > best_area and area > 1000:
                                best_area = area
                                best_mask = mask_arr
                                print(f"   âœ“ SAM3æ‰¾åˆ°: {prompt}, é¢ç§¯: {area}")
                except:
                    pass
            
            if best_mask is not None:
                return best_mask
                
        except Exception as e:
            print(f"   SAM3å¤±è´¥: {e}")
        
        return self._segment_beam_fallback(img)
    
    def _segment_beam_fallback(self, img: np.ndarray) -> np.ndarray:
        """å¤‡ç”¨æ‚¬è‡‚æ¢åˆ†å‰²"""
        print("   ä½¿ç”¨å¤‡ç”¨æ–¹æ³•åˆ†å‰²æ‚¬è‡‚æ¢")
        h, w = img.shape[:2]
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        
        # åœ¨å·¦ä¾§åŒºåŸŸæŸ¥æ‰¾
        left_region = edges[:, :int(w*0.4)]
        
        # æ‰¾è½®å»“
        contours, _ = cv2.findContours(left_region, cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_NONE)  # APPROX_NONEä¿ç•™æ‰€æœ‰ç‚¹
        
        beam_mask = np.zeros((h, w), dtype=np.uint8)
        
        if contours:
            # æ‰¾æœ€å¤§è½®å»“
            largest = max(contours, key=cv2.contourArea)
            if cv2.contourArea(largest) > 500:
                cv2.drawContours(beam_mask[:, :int(w*0.4)], [largest], -1, 255, -1)
                print(f"   âœ“ æ‰¾åˆ°æ‚¬è‡‚æ¢, é¢ç§¯: {cv2.contourArea(largest)}")
        
        return beam_mask
    
    def _integrate_masks(self, h: int, w: int, text_mask: np.ndarray,
                         color_masks: dict, beam_mask: np.ndarray) -> dict:
        """æ•´åˆæ‰€æœ‰maskï¼Œç¡®ä¿æ— é‡å """
        
        # ä¼˜å…ˆçº§ï¼šæ–‡å­— > çº¢è‰² > è“è‰² > æ‚¬è‡‚æ¢ > é»‘è‰² > èƒŒæ™¯
        final = {
            "L1_text": text_mask.copy(),
            "L2_red": np.zeros((h, w), dtype=np.uint8),
            "L3_blue": np.zeros((h, w), dtype=np.uint8),
            "L4_beam": np.zeros((h, w), dtype=np.uint8),
            "L5_black": np.zeros((h, w), dtype=np.uint8),
            "L6_background": np.zeros((h, w), dtype=np.uint8)
        }
        
        used = text_mask.copy()
        
        # çº¢è‰²
        if "red" in color_masks:
            available = cv2.bitwise_and(color_masks["red"], cv2.bitwise_not(used))
            final["L2_red"] = available
            used = cv2.bitwise_or(used, available)
        
        # è“è‰²
        if "blue" in color_masks:
            available = cv2.bitwise_and(color_masks["blue"], cv2.bitwise_not(used))
            final["L3_blue"] = available
            used = cv2.bitwise_or(used, available)
        
        # æ‚¬è‡‚æ¢
        if beam_mask is not None:
            available = cv2.bitwise_and(beam_mask, cv2.bitwise_not(used))
            final["L4_beam"] = available
            used = cv2.bitwise_or(used, available)
        
        # é»‘è‰²
        if "black" in color_masks:
            available = cv2.bitwise_and(color_masks["black"], cv2.bitwise_not(used))
            final["L5_black"] = available
            used = cv2.bitwise_or(used, available)
        
        # èƒŒæ™¯
        final["L6_background"] = cv2.bitwise_not(used)
        
        # éªŒè¯æ— é‡å 
        total = sum(np.sum(m > 0) for m in final.values())
        expected = h * w
        if abs(total - expected) < 10:
            print("   âœ… éªŒè¯é€šè¿‡ï¼šæ— é‡å ")
        
        return final
    
    def _anti_alias_mask(self, mask: np.ndarray) -> np.ndarray:
        """è¾¹ç¼˜æŠ—é”¯é½¿å¤„ç†"""
        # ä½¿ç”¨é«˜æ–¯æ¨¡ç³Šè½»å¾®å¹³æ»‘è¾¹ç¼˜
        blurred = cv2.GaussianBlur(mask.astype(np.float32), (3, 3), 0.5)
        
        # é‡æ–°äºŒå€¼åŒ–ä½†ä¿ç•™è¾¹ç¼˜è¿‡æ¸¡
        result = np.where(blurred > 200, 255, 
                         np.where(blurred > 50, blurred, 0))
        
        return result.astype(np.uint8)
    
    def _save_overlay_preview(self, img: np.ndarray, masks: dict, 
                               output_path: Path):
        """ä¿å­˜å åŠ é¢„è§ˆå›¾"""
        overlay = img.copy()
        
        colors = {
            "L1_text": (255, 255, 0),    # é»„è‰²
            "L2_red": (0, 0, 255),        # çº¢è‰²
            "L3_blue": (255, 0, 0),       # è“è‰²
            "L4_beam": (128, 128, 128),   # ç°è‰²
            "L5_black": (0, 255, 0),      # ç»¿è‰²æ ‡æ³¨é»‘è‰²åŒºåŸŸ
        }
        
        for layer_name, color in colors.items():
            if layer_name in masks:
                mask = masks[layer_name]
                colored = np.zeros_like(overlay)
                colored[:] = color
                overlay = np.where(mask[:,:,np.newaxis] > 0,
                                  cv2.addWeighted(overlay, 0.5, colored, 0.5, 0),
                                  overlay)
        
        cv2.imwrite(str(output_path), overlay, [cv2.IMWRITE_PNG_COMPRESSION, 0])
        print(f"   é¢„è§ˆå·²ä¿å­˜: {output_path}")


def main():
    generator = HighQualityMaskGenerator()
    result = generator.generate_high_quality_masks(
        "/Volumes/Seagate/SAM3/01_input/ç§‘ç ”ç»˜å›¾1.png"
    )
    print(f"\nè¾“å‡ºç›®å½•: {result['output_dir']}")


if __name__ == "__main__":
    main()
