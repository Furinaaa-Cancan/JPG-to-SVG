#!/usr/bin/env python3
"""
ç§‘ç ”ç»˜å›¾çŸ¢é‡åŒ–å¤„ç†å™¨
æ ¸å¿ƒæ€è·¯ï¼šæ–‡å­—ä¸å›¾å½¢åˆ†ç¦»å¤„ç†

Pipeline:
1. æ–‡å­—æ£€æµ‹ä¸æå– (OCR)
2. æ–‡å­—åŒºåŸŸmaskç”Ÿæˆ
3. å›¾å½¢åŒºåŸŸåˆ†å‰² (SAM3)
4. å‡ ä½•å›¾å½¢è¯†åˆ« (çº¿/çŸ©å½¢/è±å½¢)
5. åˆ†å±‚SVGç”Ÿæˆ
"""

import sys
import cv2
import numpy as np
from PIL import Image
from pathlib import Path
import json
from datetime import datetime

# æ·»åŠ SAM3è·¯å¾„
sys.path.insert(0, "/Volumes/Seagate/SAM3")


class ScientificFigureProcessor:
    """ç§‘ç ”å›¾å¤„ç†å™¨"""
    
    def __init__(self):
        self.ocr_engine = None
        self.sam3_model = None
        
    def analyze_image(self, image_path: str) -> dict:
        """
        ç¬¬ä¸€æ­¥ï¼šåˆ†æå›¾åƒç»“æ„
        è¯†åˆ«æ–‡å­—åŒºåŸŸã€å›¾å½¢åŒºåŸŸã€è¿æ¥çº¿
        """
        print("\n" + "="*60)
        print("ğŸ“Š STEP 1: å›¾åƒç»“æ„åˆ†æ")
        print("="*60)
        
        img = cv2.imread(image_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h, w = img.shape[:2]
        
        analysis = {
            "size": (w, h),
            "text_regions": [],
            "graphic_regions": [],
            "line_regions": [],
            "color_analysis": {}
        }
        
        # 1. é¢œè‰²åˆ†æ
        print("\nğŸ¨ é¢œè‰²åˆ†æ...")
        analysis["color_analysis"] = self._analyze_colors(img_rgb)
        
        # 2. è¾¹ç¼˜æ£€æµ‹ - è¯†åˆ«çº¿æ¡å’Œå‡ ä½•å½¢çŠ¶
        print("ğŸ“ è¾¹ç¼˜æ£€æµ‹...")
        edges = cv2.Canny(img, 50, 150)
        analysis["edge_density"] = np.sum(edges > 0) / (w * h)
        
        # 3. è¿é€šåŸŸåˆ†æ
        print("ğŸ”— è¿é€šåŸŸåˆ†æ...")
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # åˆ†ç±»è¿é€šåŸŸ
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < 50:  # å¤ªå°ï¼Œå¿½ç•¥
                continue
            
            x, y, cw, ch = cv2.boundingRect(cnt)
            aspect_ratio = cw / ch if ch > 0 else 0
            
            region_info = {
                "bbox": [x, y, cw, ch],
                "area": area,
                "aspect_ratio": aspect_ratio
            }
            
            # å¯å‘å¼åˆ†ç±»
            if aspect_ratio > 3 and ch < 30:
                # å®½æ‰å½¢çŠ¶ï¼Œå¯èƒ½æ˜¯æ–‡å­—
                region_info["type"] = "text_candidate"
                analysis["text_regions"].append(region_info)
            elif 0.8 < aspect_ratio < 1.2 and area > 500:
                # æ¥è¿‘æ­£æ–¹å½¢ï¼Œå¯èƒ½æ˜¯å›¾å½¢å…ƒç´ 
                region_info["type"] = "graphic_candidate"
                analysis["graphic_regions"].append(region_info)
            else:
                analysis["graphic_regions"].append(region_info)
        
        print(f"\nğŸ“‹ åˆ†æç»“æœ:")
        print(f"   - å›¾åƒå°ºå¯¸: {w}x{h}")
        print(f"   - è¾¹ç¼˜å¯†åº¦: {analysis['edge_density']:.2%}")
        print(f"   - æ–‡å­—å€™é€‰åŒºåŸŸ: {len(analysis['text_regions'])}")
        print(f"   - å›¾å½¢å€™é€‰åŒºåŸŸ: {len(analysis['graphic_regions'])}")
        
        return analysis
    
    def _analyze_colors(self, img_rgb: np.ndarray) -> dict:
        """åˆ†æå›¾åƒä¸»è¦é¢œè‰²"""
        # è½¬HSVæ›´å®¹æ˜“åˆ†æ
        img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
        
        # æ£€æµ‹ä¸»è¦é¢œè‰²åŒºåŸŸ
        colors = {
            "red": {"lower": (0, 100, 100), "upper": (10, 255, 255)},
            "blue": {"lower": (100, 100, 100), "upper": (130, 255, 255)},
            "white": {"lower": (0, 0, 200), "upper": (180, 30, 255)},
            "black": {"lower": (0, 0, 0), "upper": (180, 255, 50)},
        }
        
        result = {}
        total_pixels = img_rgb.shape[0] * img_rgb.shape[1]
        
        for color_name, ranges in colors.items():
            mask = cv2.inRange(img_hsv, ranges["lower"], ranges["upper"])
            pixel_count = np.sum(mask > 0)
            result[color_name] = {
                "pixel_count": int(pixel_count),
                "percentage": pixel_count / total_pixels
            }
        
        return result
    
    def detect_text_regions(self, image_path: str) -> list:
        """
        ç¬¬äºŒæ­¥ï¼šæ£€æµ‹æ–‡å­—åŒºåŸŸ
        ä½¿ç”¨å¤šç§æ–¹æ³•ï¼š
        1. MSER (Maximally Stable Extremal Regions)
        2. å½¢æ€å­¦æ“ä½œ
        3. OCRå¼•æ“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        """
        print("\n" + "="*60)
        print("ğŸ“ STEP 2: æ–‡å­—åŒºåŸŸæ£€æµ‹")
        print("="*60)
        
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        h, w = img.shape[:2]
        
        text_regions = []
        
        # æ–¹æ³•1: MSERæ£€æµ‹
        print("\nğŸ” æ–¹æ³•1: MSERæ–‡å­—æ£€æµ‹...")
        mser = cv2.MSER_create()
        mser.setMinArea(60)
        mser.setMaxArea(5000)
        
        regions, _ = mser.detectRegions(gray)
        
        # åˆå¹¶é‡å åŒºåŸŸ
        hulls = [cv2.convexHull(p.reshape(-1, 1, 2)) for p in regions]
        
        # è·å–è¾¹ç•Œæ¡†
        mser_boxes = []
        for hull in hulls:
            x, y, bw, bh = cv2.boundingRect(hull)
            # è¿‡æ»¤å¤ªå¤§æˆ–å¤ªå°çš„åŒºåŸŸ
            if 10 < bw < w*0.5 and 8 < bh < 50:
                mser_boxes.append([x, y, bw, bh])
        
        print(f"   MSERæ£€æµ‹åˆ° {len(mser_boxes)} ä¸ªå€™é€‰åŒºåŸŸ")
        
        # æ–¹æ³•2: å½¢æ€å­¦æ–‡å­—æ£€æµ‹
        print("\nğŸ” æ–¹æ³•2: å½¢æ€å­¦æ–‡å­—æ£€æµ‹...")
        
        # äºŒå€¼åŒ–
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # æ°´å¹³è†¨èƒ€è¿æ¥æ–‡å­—
        kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))
        dilated = cv2.dilate(binary, kernel_h, iterations=1)
        
        # å‚ç›´è†¨èƒ€
        kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 3))
        dilated = cv2.dilate(dilated, kernel_v, iterations=1)
        
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        morph_boxes = []
        for cnt in contours:
            x, y, bw, bh = cv2.boundingRect(cnt)
            aspect = bw / bh if bh > 0 else 0
            # æ–‡å­—é€šå¸¸æ˜¯å®½æ‰çš„
            if aspect > 1.5 and 8 < bh < 40 and bw > 20:
                morph_boxes.append([x, y, bw, bh])
        
        print(f"   å½¢æ€å­¦æ£€æµ‹åˆ° {len(morph_boxes)} ä¸ªå€™é€‰åŒºåŸŸ")
        
        # åˆå¹¶ä¸¤ç§æ–¹æ³•çš„ç»“æœ
        all_boxes = mser_boxes + morph_boxes
        merged_boxes = self._merge_overlapping_boxes(all_boxes)
        
        print(f"\nâœ… åˆå¹¶åå…± {len(merged_boxes)} ä¸ªæ–‡å­—åŒºåŸŸ")
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        for box in merged_boxes:
            text_regions.append({
                "bbox": box,
                "confidence": 0.8,
                "text": None  # éœ€è¦OCRå¡«å……
            })
        
        return text_regions
    
    def _merge_overlapping_boxes(self, boxes: list, overlap_thresh: float = 0.3) -> list:
        """åˆå¹¶é‡å çš„è¾¹ç•Œæ¡†"""
        if len(boxes) == 0:
            return []
        
        boxes = np.array(boxes)
        
        # è½¬æ¢ä¸º (x1, y1, x2, y2) æ ¼å¼
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 0] + boxes[:, 2]
        y2 = boxes[:, 1] + boxes[:, 3]
        
        areas = (x2 - x1) * (y2 - y1)
        indices = np.argsort(y1)
        
        merged = []
        while len(indices) > 0:
            i = indices[0]
            merged.append([int(x1[i]), int(y1[i]), int(x2[i] - x1[i]), int(y2[i] - y1[i])])
            
            # è®¡ç®—IoU
            xx1 = np.maximum(x1[i], x1[indices[1:]])
            yy1 = np.maximum(y1[i], y1[indices[1:]])
            xx2 = np.minimum(x2[i], x2[indices[1:]])
            yy2 = np.minimum(y2[i], y2[indices[1:]])
            
            inter_w = np.maximum(0, xx2 - xx1)
            inter_h = np.maximum(0, yy2 - yy1)
            intersection = inter_w * inter_h
            
            iou = intersection / (areas[i] + areas[indices[1:]] - intersection + 1e-6)
            
            # ä¿ç•™IoUå°äºé˜ˆå€¼çš„
            remaining = np.where(iou < overlap_thresh)[0]
            indices = indices[remaining + 1]
        
        return merged
    
    def create_text_mask(self, image_path: str, text_regions: list, padding: int = 3) -> np.ndarray:
        """
        ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºæ–‡å­—åŒºåŸŸMask
        ç”¨äºåç»­å°†æ–‡å­—ä»å›¾åƒä¸­åˆ†ç¦»
        """
        print("\n" + "="*60)
        print("ğŸ­ STEP 3: ç”Ÿæˆæ–‡å­—Mask")
        print("="*60)
        
        img = cv2.imread(image_path)
        h, w = img.shape[:2]
        
        # åˆ›å»ºmask
        text_mask = np.zeros((h, w), dtype=np.uint8)
        
        for region in text_regions:
            x, y, bw, bh = region["bbox"]
            # æ·»åŠ padding
            x1 = max(0, x - padding)
            y1 = max(0, y - padding)
            x2 = min(w, x + bw + padding)
            y2 = min(h, y + bh + padding)
            
            text_mask[y1:y2, x1:x2] = 255
        
        # ç¨å¾®è†¨èƒ€ç¡®ä¿è¦†ç›–å®Œæ•´
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        text_mask = cv2.dilate(text_mask, kernel, iterations=1)
        
        coverage = np.sum(text_mask > 0) / (w * h)
        print(f"   æ–‡å­—maskè¦†ç›–ç‡: {coverage:.1%}")
        
        return text_mask
    
    def detect_geometric_elements(self, image_path: str, text_mask: np.ndarray) -> dict:
        """
        ç¬¬å››æ­¥ï¼šæ£€æµ‹å‡ ä½•å›¾å½¢å…ƒç´ 
        - ç›´çº¿
        - çŸ©å½¢
        - è±å½¢
        - é”¯é½¿çº¿ï¼ˆç”µé˜»ç¬¦å·ï¼‰
        - ç®­å¤´
        """
        print("\n" + "="*60)
        print("ğŸ“ STEP 4: å‡ ä½•å›¾å½¢æ£€æµ‹")
        print("="*60)
        
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        h, w = img.shape[:2]
        
        # æ’é™¤æ–‡å­—åŒºåŸŸ
        gray_no_text = gray.copy()
        gray_no_text[text_mask > 0] = 255  # å°†æ–‡å­—åŒºåŸŸè®¾ä¸ºç™½è‰²
        
        elements = {
            "lines": [],
            "rectangles": [],
            "diamonds": [],
            "arrows": [],
            "zigzags": []  # ç”µé˜»ç¬¦å·
        }
        
        # 1. ç›´çº¿æ£€æµ‹ (Hough)
        print("\nğŸ” æ£€æµ‹ç›´çº¿...")
        edges = cv2.Canny(gray_no_text, 50, 150)
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=30, maxLineGap=10)
        
        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                length = np.sqrt((x2-x1)**2 + (y2-y1)**2)
                angle = np.degrees(np.arctan2(y2-y1, x2-x1))
                elements["lines"].append({
                    "start": (int(x1), int(y1)),
                    "end": (int(x2), int(y2)),
                    "length": float(length),
                    "angle": float(angle)
                })
        
        print(f"   æ£€æµ‹åˆ° {len(elements['lines'])} æ¡ç›´çº¿")
        
        # 2. çŸ©å½¢æ£€æµ‹
        print("\nğŸ” æ£€æµ‹çŸ©å½¢...")
        _, binary = cv2.threshold(gray_no_text, 200, 255, cv2.THRESH_BINARY_INV)
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < 100:
                continue
            
            # å¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.02 * cv2.arcLength(cnt, True)
            approx = cv2.approxPolyDP(cnt, epsilon, True)
            
            if len(approx) == 4:
                # æ£€æŸ¥æ˜¯å¦æ¥è¿‘çŸ©å½¢
                x, y, bw, bh = cv2.boundingRect(approx)
                rect_area = bw * bh
                if area / rect_area > 0.8:  # å¡«å……ç‡é«˜ï¼Œæ˜¯çŸ©å½¢
                    elements["rectangles"].append({
                        "bbox": [int(x), int(y), int(bw), int(bh)],
                        "vertices": approx.reshape(-1, 2).tolist()
                    })
                else:
                    # å¯èƒ½æ˜¯è±å½¢
                    elements["diamonds"].append({
                        "vertices": approx.reshape(-1, 2).tolist(),
                        "center": (int(x + bw/2), int(y + bh/2))
                    })
        
        print(f"   æ£€æµ‹åˆ° {len(elements['rectangles'])} ä¸ªçŸ©å½¢")
        print(f"   æ£€æµ‹åˆ° {len(elements['diamonds'])} ä¸ªè±å½¢")
        
        # 3. ç®­å¤´æ£€æµ‹ï¼ˆé€šè¿‡ä¸‰è§’å½¢ç«¯ç‚¹ï¼‰
        print("\nğŸ” æ£€æµ‹ç®­å¤´...")
        for cnt in contours:
            epsilon = 0.05 * cv2.arcLength(cnt, True)
            approx = cv2.approxPolyDP(cnt, epsilon, True)
            
            if len(approx) == 3:  # ä¸‰è§’å½¢
                area = cv2.contourArea(cnt)
                if 50 < area < 500:  # ç®­å¤´å¤§å°èŒƒå›´
                    elements["arrows"].append({
                        "vertices": approx.reshape(-1, 2).tolist()
                    })
        
        print(f"   æ£€æµ‹åˆ° {len(elements['arrows'])} ä¸ªç®­å¤´")
        
        return elements
    
    def segment_with_sam3(self, image_path: str, text_mask: np.ndarray) -> list:
        """
        ç¬¬äº”æ­¥ï¼šä½¿ç”¨SAM3åˆ†å‰²å¤æ‚åŒºåŸŸ
        å¯¹äºæ— æ³•ç”¨å‡ ä½•æ–¹æ³•å¤„ç†çš„åŒºåŸŸ
        """
        print("\n" + "="*60)
        print("ğŸ§  STEP 5: SAM3æ™ºèƒ½åˆ†å‰²")
        print("="*60)
        
        try:
            sys.path.insert(0, "/Volumes/Seagate/SAM3/æ¨¡å‹åº“/01_SAM3æ ¸å¿ƒæ¨¡å‹")
            from sam3.model_builder import build_sam3_image_model
            from sam3.model.sam3_image_processor import Sam3Processor
            
            print("åŠ è½½SAM3æ¨¡å‹...")
            model = build_sam3_image_model(device="cpu")
            processor = Sam3Processor(model, device="cpu")
            
            img = Image.open(image_path)
            state = processor.set_image(img)
            
            # é’ˆå¯¹ç§‘ç ”å›¾çš„å…³é”®prompt
            prompts = [
                "3D beam structure",
                "strain gauge", 
                "electronic circuit",
                "resistor symbol",
                "diamond bridge circuit",
                "connecting wire"
            ]
            
            masks = []
            for prompt in prompts:
                print(f"   åˆ†å‰²: {prompt}")
                try:
                    state = processor.set_text_prompt(prompt, state)
                    if state and "masks" in state:
                        for mask in state["masks"]:
                            mask_array = np.array(mask)
                            if np.sum(mask_array) > 100:
                                masks.append({
                                    "prompt": prompt,
                                    "mask": mask_array,
                                    "area": int(np.sum(mask_array > 0))
                                })
                except Exception as e:
                    print(f"      è­¦å‘Š: {e}")
            
            print(f"\nâœ… SAM3åˆ†å‰²å¾—åˆ° {len(masks)} ä¸ªmask")
            return masks
            
        except Exception as e:
            print(f"âš ï¸ SAM3åŠ è½½å¤±è´¥: {e}")
            print("   å°†è·³è¿‡SAM3åˆ†å‰²ï¼Œä½¿ç”¨çº¯å‡ ä½•æ–¹æ³•")
            return []
    
    def generate_svg(self, image_path: str, text_regions: list, 
                     geometric_elements: dict, sam3_masks: list,
                     output_path: str) -> str:
        """
        ç¬¬å…­æ­¥ï¼šç”Ÿæˆåˆ†å±‚SVG
        """
        print("\n" + "="*60)
        print("ğŸ“„ STEP 6: ç”Ÿæˆåˆ†å±‚SVG")
        print("="*60)
        
        img = cv2.imread(image_path)
        h, w = img.shape[:2]
        
        svg_parts = []
        svg_parts.append(f'<?xml version="1.0" encoding="UTF-8"?>')
        svg_parts.append(f'<svg xmlns="http://www.w3.org/2000/svg" width="{w}" height="{h}" viewBox="0 0 {w} {h}">')
        
        # èƒŒæ™¯å±‚
        svg_parts.append('  <g id="background">')
        svg_parts.append(f'    <rect x="0" y="0" width="{w}" height="{h}" fill="white"/>')
        svg_parts.append('  </g>')
        
        # å‡ ä½•å›¾å½¢å±‚
        svg_parts.append('  <g id="geometric-elements">')
        
        # ç›´çº¿
        for line in geometric_elements.get("lines", [])[:50]:  # é™åˆ¶æ•°é‡
            x1, y1 = line["start"]
            x2, y2 = line["end"]
            svg_parts.append(f'    <line x1="{x1}" y1="{y1}" x2="{x2}" y2="{y2}" stroke="black" stroke-width="1"/>')
        
        # çŸ©å½¢
        for rect in geometric_elements.get("rectangles", []):
            x, y, bw, bh = rect["bbox"]
            svg_parts.append(f'    <rect x="{x}" y="{y}" width="{bw}" height="{bh}" fill="none" stroke="black" stroke-width="1"/>')
        
        # è±å½¢
        for diamond in geometric_elements.get("diamonds", []):
            points = " ".join([f"{p[0]},{p[1]}" for p in diamond["vertices"]])
            svg_parts.append(f'    <polygon points="{points}" fill="none" stroke="black" stroke-width="1"/>')
        
        svg_parts.append('  </g>')
        
        # æ–‡å­—å±‚ï¼ˆå ä½ç¬¦ï¼Œéœ€è¦OCRå¡«å……ï¼‰
        svg_parts.append('  <g id="text-layer">')
        for i, region in enumerate(text_regions):
            x, y, bw, bh = region["bbox"]
            text_content = region.get("text", f"[Text_{i}]")
            # æ–‡å­—ä½ç½®åœ¨boxåº•éƒ¨å±…ä¸­
            svg_parts.append(f'    <text x="{x + bw//2}" y="{y + bh - 2}" font-size="{min(bh-2, 14)}" text-anchor="middle" fill="black">{text_content}</text>')
        svg_parts.append('  </g>')
        
        svg_parts.append('</svg>')
        
        svg_content = '\n'.join(svg_parts)
        
        # ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(svg_content)
        
        print(f"âœ… SVGå·²ä¿å­˜: {output_path}")
        print(f"   - ç›´çº¿: {len(geometric_elements.get('lines', []))}")
        print(f"   - çŸ©å½¢: {len(geometric_elements.get('rectangles', []))}")
        print(f"   - è±å½¢: {len(geometric_elements.get('diamonds', []))}")
        print(f"   - æ–‡å­—åŒºåŸŸ: {len(text_regions)}")
        
        return output_path
    
    def process(self, image_path: str, output_dir: str = None) -> dict:
        """
        å®Œæ•´å¤„ç†æµç¨‹
        """
        print("\n" + "="*70)
        print("ğŸ¯ ç§‘ç ”ç»˜å›¾çŸ¢é‡åŒ–å¤„ç†å™¨")
        print("="*70)
        print(f"è¾“å…¥: {image_path}")
        
        if output_dir is None:
            output_dir = "/Volumes/Seagate/SAM3/02_output/scientific"
        
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Step 1: åˆ†æå›¾åƒ
        analysis = self.analyze_image(image_path)
        
        # Step 2: æ£€æµ‹æ–‡å­—åŒºåŸŸ
        text_regions = self.detect_text_regions(image_path)
        
        # Step 3: ç”Ÿæˆæ–‡å­—mask
        text_mask = self.create_text_mask(image_path, text_regions)
        
        # ä¿å­˜æ–‡å­—mask
        mask_path = f"{output_dir}/text_mask_{timestamp}.png"
        cv2.imwrite(mask_path, text_mask)
        print(f"   æ–‡å­—maskå·²ä¿å­˜: {mask_path}")
        
        # Step 4: æ£€æµ‹å‡ ä½•å…ƒç´ 
        geometric_elements = self.detect_geometric_elements(image_path, text_mask)
        
        # Step 5: SAM3åˆ†å‰²ï¼ˆå¯é€‰ï¼‰
        sam3_masks = []  # self.segment_with_sam3(image_path, text_mask)
        
        # Step 6: ç”ŸæˆSVG
        svg_path = f"{output_dir}/scientific_{timestamp}.svg"
        self.generate_svg(image_path, text_regions, geometric_elements, sam3_masks, svg_path)
        
        # ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾
        self._create_visualization(image_path, text_regions, geometric_elements, 
                                   f"{output_dir}/analysis_{timestamp}.png")
        
        return {
            "analysis": analysis,
            "text_regions": len(text_regions),
            "geometric_elements": {k: len(v) for k, v in geometric_elements.items()},
            "output_svg": svg_path
        }
    
    def _create_visualization(self, image_path: str, text_regions: list, 
                              geometric_elements: dict, output_path: str):
        """åˆ›å»ºåˆ†æå¯è§†åŒ–å›¾"""
        img = cv2.imread(image_path)
        vis = img.copy()
        
        # ç»˜åˆ¶æ–‡å­—åŒºåŸŸï¼ˆç»¿è‰²ï¼‰
        for region in text_regions:
            x, y, w, h = region["bbox"]
            cv2.rectangle(vis, (x, y), (x+w, y+h), (0, 255, 0), 2)
        
        # ç»˜åˆ¶æ£€æµ‹åˆ°çš„ç›´çº¿ï¼ˆè“è‰²ï¼‰
        for line in geometric_elements.get("lines", [])[:30]:
            pt1 = line["start"]
            pt2 = line["end"]
            cv2.line(vis, pt1, pt2, (255, 0, 0), 2)
        
        # ç»˜åˆ¶çŸ©å½¢ï¼ˆçº¢è‰²ï¼‰
        for rect in geometric_elements.get("rectangles", []):
            x, y, w, h = rect["bbox"]
            cv2.rectangle(vis, (x, y), (x+w, y+h), (0, 0, 255), 2)
        
        cv2.imwrite(output_path, vis)
        print(f"   å¯è§†åŒ–å›¾å·²ä¿å­˜: {output_path}")


def main():
    processor = ScientificFigureProcessor()
    
    # å¤„ç†ç§‘ç ”ç»˜å›¾
    image_path = "/Volumes/Seagate/SAM3/01_input/ç§‘ç ”ç»˜å›¾1.png"
    result = processor.process(image_path)
    
    print("\n" + "="*70)
    print("ğŸ“Š å¤„ç†å®Œæˆ")
    print("="*70)
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()
