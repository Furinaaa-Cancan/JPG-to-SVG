#!/usr/bin/env python3
"""
VAEæ½œåœ¨ç©ºé—´çŸ¢é‡åŒ–
åˆ©ç”¨SDçš„VAEåœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œæ™ºèƒ½åˆ†å‰²
- è®¡ç®—é‡å°ï¼ˆæ½œåœ¨ç©ºé—´æ˜¯åŸå›¾1/64ï¼‰
- æ›´è¯­ä¹‰åŒ–çš„åˆ†å‰²ï¼ˆVAEå­¦ä¹ äº†å›¾åƒçš„è¯­ä¹‰è¡¨ç¤ºï¼‰
- æ–‡ä»¶æ›´å°
"""

import torch
import numpy as np
import cv2
from PIL import Image
from pathlib import Path
import svgwrite
import time
from sklearn.cluster import KMeans
from diffusers import AutoencoderKL


class VAEVectorizer:
    """VAEæ½œåœ¨ç©ºé—´çŸ¢é‡åŒ–"""
    
    def __init__(self, model_path: str = None):
        print("\nğŸš€ Loading SD VAE...")
        
        # ä½¿ç”¨æœ¬åœ°SDXLçš„VAE
        if model_path is None:
            model_path = "/Volumes/Seagate/SAM3/æ¨¡å‹åº“/02_StableDiffusionæ¨¡å‹/åŸºç¡€æ¨¡å‹/sdxl-base"
        
        self.device = "mps" if torch.backends.mps.is_available() else "cpu"
        
        self.vae = AutoencoderKL.from_pretrained(
            model_path,
            subfolder="vae",
            torch_dtype=torch.float32,
            local_files_only=True
        ).to(self.device)
        self.vae.eval()
        print(f"âœ… VAE loaded on {self.device}")
    
    def vectorize(self, image_path: str, output_dir: str = "02_è¾“å‡ºç»“æœ/vae_svg"):
        """VAEæ½œåœ¨ç©ºé—´çŸ¢é‡åŒ–"""
        
        print("\n" + "="*70)
        print("ğŸ’ VAE LATENT SPACE VECTORIZATION")
        print("="*70)
        
        start_time = time.time()
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½å›¾åƒ
        img_pil = Image.open(image_path).convert("RGB")
        img_array = np.array(img_pil)
        orig_h, orig_w = img_array.shape[:2]
        
        print(f"\nğŸ“· Original: {orig_w}x{orig_h}")
        
        # è°ƒæ•´åˆ°VAEè¦æ±‚çš„å°ºå¯¸ï¼ˆ8çš„å€æ•°ï¼‰
        new_w = (orig_w // 8) * 8
        new_h = (orig_h // 8) * 8
        img_resized = img_pil.resize((new_w, new_h), Image.LANCZOS)
        
        print(f"   Resized: {new_w}x{new_h}")
        
        # Step 1: ç¼–ç åˆ°æ½œåœ¨ç©ºé—´
        print("\nğŸ”§ Step 1: Encoding to latent space...")
        latents = self.encode_image(img_resized)
        latent_h, latent_w = latents.shape[2], latents.shape[3]
        print(f"   Latent shape: {latents.shape} ({latent_w}x{latent_h})")
        
        # Step 2: åœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œè¯­ä¹‰èšç±»
        print("\nğŸ¯ Step 2: Semantic clustering in latent space...")
        n_clusters = 64  # å°‘é‡èšç±»ï¼Œä½†è¯­ä¹‰æ›´å¼º
        cluster_map = self.cluster_latents(latents, n_clusters)
        
        # Step 3: ä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
        print("\nğŸ“ Step 3: Upsampling cluster map...")
        cluster_map_full = cv2.resize(
            cluster_map.astype(np.float32),
            (orig_w, orig_h),
            interpolation=cv2.INTER_NEAREST
        ).astype(int)
        
        # Step 4: æå–æ¯ä¸ªèšç±»çš„åŒºåŸŸå’Œé¢œè‰²
        print("\nğŸ¨ Step 4: Extracting regions...")
        regions = self.extract_regions(cluster_map_full, img_array, n_clusters)
        print(f"   Extracted {len(regions)} regions")
        
        # Step 5: ç”ŸæˆSVG
        print("\nâœ¨ Step 5: Generating SVG...")
        svg_path = output_path / "vae_vector.svg"
        stats = self.create_svg(regions, orig_w, orig_h, str(svg_path))
        
        # å¯¹æ¯”HTML
        self.create_html(image_path, str(svg_path), output_path, stats)
        
        process_time = time.time() - start_time
        
        print(f"\n" + "="*70)
        print(f"âœ… VAE VECTORIZATION COMPLETE!")
        print(f"   Paths: {stats['paths']}")
        print(f"   Size: {stats['size_kb']:.1f} KB")
        print(f"   Time: {process_time:.1f}s")
        print("="*70)
        
        import subprocess
        subprocess.run(["open", str(output_path / "result.html")])
        
        return stats
    
    @torch.no_grad()
    def encode_image(self, image: Image.Image) -> torch.Tensor:
        """å°†å›¾åƒç¼–ç åˆ°æ½œåœ¨ç©ºé—´"""
        
        # è½¬æ¢ä¸ºtensor
        img_tensor = torch.from_numpy(np.array(image)).float()
        img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # [1, 3, H, W]
        img_tensor = (img_tensor / 127.5) - 1.0  # å½’ä¸€åŒ–åˆ°[-1, 1]
        img_tensor = img_tensor.to(self.device)
        
        # ç¼–ç 
        latents = self.vae.encode(img_tensor).latent_dist.sample()
        
        return latents
    
    def cluster_latents(self, latents: torch.Tensor, n_clusters: int) -> np.ndarray:
        """åœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œèšç±»"""
        
        # latents shape: [1, 4, H, W]
        latent_np = latents.cpu().numpy()[0]  # [4, H, W]
        
        h, w = latent_np.shape[1], latent_np.shape[2]
        
        # é‡å¡‘ä¸º [H*W, 4]
        features = latent_np.transpose(1, 2, 0).reshape(-1, 4)
        
        # K-meansèšç±»
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=3, max_iter=50)
        labels = kmeans.fit_predict(features)
        
        # é‡å¡‘å› [H, W]
        cluster_map = labels.reshape(h, w)
        
        return cluster_map
    
    def extract_regions(self, cluster_map: np.ndarray, img: np.ndarray, n_clusters: int) -> list:
        """æå–æ¯ä¸ªèšç±»çš„åŒºåŸŸ"""
        
        regions = []
        h, w = cluster_map.shape
        
        for cid in range(n_clusters):
            # åˆ›å»ºmask
            mask = (cluster_map == cid).astype(np.uint8) * 255
            area = np.sum(mask > 0)
            
            if area < 100:
                continue
            
            # æå–é¢œè‰²
            pixels = img[mask > 127]
            if len(pixels) > 0:
                color = np.mean(pixels, axis=0).astype(int)
                
                # æ‰¾è¿é€šç»„ä»¶
                n_labels, labeled = cv2.connectedComponents(mask)
                
                for lid in range(1, n_labels):
                    component_mask = (labeled == lid).astype(np.uint8) * 255
                    component_area = np.sum(component_mask > 0)
                    
                    if component_area > 50:
                        # æå–è¯¥ç»„ä»¶çš„ç²¾ç¡®é¢œè‰²
                        component_pixels = img[component_mask > 127]
                        if len(component_pixels) > 0:
                            component_color = np.mean(component_pixels, axis=0).astype(int)
                            
                            regions.append({
                                'mask': component_mask,
                                'color': f"#{component_color[0]:02x}{component_color[1]:02x}{component_color[2]:02x}",
                                'area': component_area
                            })
        
        return regions
    
    def create_svg(self, regions: list, width: int, height: int, output_path: str) -> dict:
        """åˆ›å»ºSVG"""
        
        dwg = svgwrite.Drawing(output_path, size=(width, height))
        dwg.viewbox(0, 0, width, height)
        
        # æŒ‰é¢ç§¯æ’åº
        regions.sort(key=lambda x: x['area'], reverse=True)
        
        paths = 0
        
        for region in regions:
            mask = region['mask']
            color = region['color']
            
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                if cv2.contourArea(contour) < 30:
                    continue
                
                # ç®€åŒ–è½®å»“
                epsilon = 2.0
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                if len(approx) >= 3:
                    points = approx.squeeze()
                    if points.ndim == 1:
                        points = points.reshape(-1, 2)
                    if len(points) < 3:
                        continue
                    
                    # ä½¿ç”¨äºŒæ¬¡è´å¡å°”æ›²çº¿å¹³æ»‘
                    path_d = self.create_smooth_path(points)
                    
                    dwg.add(dwg.path(d=path_d, fill=color, stroke="none"))
                    paths += 1
        
        dwg.save()
        
        return {
            'paths': paths,
            'size_kb': Path(output_path).stat().st_size / 1024
        }
    
    def create_smooth_path(self, points: np.ndarray) -> str:
        """åˆ›å»ºå¹³æ»‘çš„è´å¡å°”æ›²çº¿è·¯å¾„"""
        
        if len(points) < 3:
            return ""
        
        path_d = f"M{points[0][0]},{points[0][1]}"
        
        for i in range(1, len(points)):
            curr = points[i]
            prev = points[i - 1]
            
            # è®¡ç®—æ§åˆ¶ç‚¹
            if i < len(points) - 1:
                next_pt = points[i + 1]
                cx = (prev[0] + curr[0] + next_pt[0]) / 3
                cy = (prev[1] + curr[1] + next_pt[1]) / 3
                path_d += f" Q{curr[0]},{curr[1]} {cx},{cy}"
            else:
                path_d += f" L{curr[0]},{curr[1]}"
        
        path_d += " Z"
        return path_d
    
    def create_html(self, original: str, svg: str, output_path: Path, stats: dict):
        """åˆ›å»ºå¯¹æ¯”HTML"""
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>VAE Vectorization</title>
            <style>
                body {{ margin:0; background:#0a0a0a; color:#fff; font-family:sans-serif; }}
                .header {{ text-align:center; padding:50px; background:linear-gradient(135deg,#00d2ff,#3a7bd5); }}
                h1 {{ font-size:3em; margin:0; }}
                .subtitle {{ margin-top:10px; opacity:0.9; }}
                .stats {{ display:flex; justify-content:center; gap:40px; margin-top:20px; }}
                .stat {{ background:rgba(0,0,0,0.3); padding:15px 30px; border-radius:25px; }}
                .grid {{ display:grid; grid-template-columns:1fr 1fr; gap:20px; padding:40px; max-width:1600px; margin:0 auto; }}
                .card {{ background:#1a1a1a; border-radius:15px; overflow:hidden; }}
                .card-header {{ padding:15px; background:#2a2a2a; font-weight:bold; text-align:center; }}
                img, object {{ width:100%; display:block; }}
                .tech {{ text-align:center; padding:30px; background:#1a1a1a; margin:20px 40px; border-radius:15px; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸ§  VAE æ½œåœ¨ç©ºé—´çŸ¢é‡åŒ–</h1>
                <div class="subtitle">åˆ©ç”¨Stable Diffusion VAEçš„è¯­ä¹‰ç†è§£èƒ½åŠ›</div>
                <div class="stats">
                    <span class="stat">ğŸ“Š {stats['paths']} è·¯å¾„</span>
                    <span class="stat">ğŸ“¦ {stats['size_kb']:.0f} KB</span>
                </div>
            </div>
            <div class="grid">
                <div class="card">
                    <div class="card-header">ğŸ“· åŸå›¾</div>
                    <img src="../../{original}">
                </div>
                <div class="card">
                    <div class="card-header">âœ¨ SVG (VAE)</div>
                    <object data="{Path(svg).name}" type="image/svg+xml"></object>
                </div>
            </div>
            <div class="tech">
                <h2>ğŸ’¡ æŠ€æœ¯åŸç†</h2>
                <p>SDçš„VAEå°†å›¾åƒå‹ç¼©åˆ°4é€šé“æ½œåœ¨ç©ºé—´ï¼ˆ1/64å¤§å°ï¼‰</p>
                <p>åœ¨æ½œåœ¨ç©ºé—´èšç±» â†’ è¯­ä¹‰æ›´å¼º + è®¡ç®—é‡æ›´å°</p>
            </div>
        </body>
        </html>
        """
        with open(output_path / "result.html", 'w') as f:
            f.write(html)


def main():
    vectorizer = VAEVectorizer()
    return vectorizer.vectorize("01_è¾“å…¥å›¾ç‰‡/Ladygaga_2.jpg")


if __name__ == "__main__":
    main()
