"""
SVG Diffusion å¢å¼ºå™¨
æµç¨‹ï¼šå·²æœ‰å›¾åƒ â†’ SDå¤„ç† â†’ é‡æ–°çŸ¢é‡åŒ–
"""

import torch
import numpy as np
from PIL import Image
from pathlib import Path
from datetime import datetime
import sys
sys.path.insert(0, "/Volumes/Seagate/SAM3/12_è¯­ä¹‰çŸ¢é‡åŒ–")

from diffusers import StableDiffusionImg2ImgPipeline, StableDiffusionXLImg2ImgPipeline
import cairosvg
from io import BytesIO


class SVGDiffusionEnhancer:
    """SVG Diffusion å¢å¼ºå™¨"""
    
    def __init__(self, device="mps"):
        self.device = device
        self.pipe = None
        
    def load_sd(self, model_type="sdxl"):
        """åŠ è½½SDæ¨¡å‹"""
        print(f"Loading {model_type.upper()}...")
        
        if model_type == "sdxl":
            self.pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(
                "stabilityai/stable-diffusion-xl-base-1.0",
                torch_dtype=torch.float32,
                use_safetensors=True
            ).to(self.device)
        else:
            self.pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
                "runwayml/stable-diffusion-v1-5",
                torch_dtype=torch.float32,
                safety_checker=None
            ).to(self.device)
        
        print("âœ… SD loaded!")
    
    def load_image(self, path: str) -> Image.Image:
        """åŠ è½½å›¾åƒï¼ˆæ”¯æŒSVGã€PNGã€JPGç­‰ï¼‰"""
        path = Path(path)
        
        if path.suffix.lower() in ['.svg', '.svgz']:
            # SVGè½¬PNG
            print(f"Converting SVG to PNG...")
            png_data = cairosvg.svg2png(url=str(path), output_width=1024, output_height=1024)
            img = Image.open(BytesIO(png_data)).convert("RGB")
        else:
            img = Image.open(path).convert("RGB")
        
        return img
    
    def process(
        self,
        input_path: str,
        prompt: str,
        negative_prompt: str = "blurry, low quality, distorted",
        strength: float = 0.5,
        guidance_scale: float = 7.5,
        num_inference_steps: int = 30,
        output_dir: str = "output"
    ):
        """
        å¤„ç†å›¾åƒ
        
        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆSVG/PNG/JPGï¼‰
            prompt: é£æ ¼/ä¿®æ”¹æç¤ºè¯
            strength: å˜åŒ–å¼ºåº¦ (0-1)ï¼Œè¶Šå¤§å˜åŒ–è¶Šå¤§
            guidance_scale: æç¤ºè¯å¼•å¯¼å¼ºåº¦
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"\n{'='*60}")
        print(f"ğŸ¨ SVG Diffusion Enhancement")
        print(f"{'='*60}")
        print(f"Input: {input_path}")
        print(f"Prompt: {prompt}")
        print(f"Strength: {strength}")
        print(f"{'='*60}\n")
        
        # åŠ è½½è¾“å…¥å›¾åƒ
        input_img = self.load_image(input_path)
        print(f"ğŸ“· Input size: {input_img.size}")
        
        # è°ƒæ•´å¤§å°ï¼ˆSDXLéœ€è¦1024ï¼ŒSD1.5éœ€è¦512ï¼‰
        target_size = 1024 if "xl" in str(type(self.pipe)).lower() else 512
        input_img = input_img.resize((target_size, target_size), Image.LANCZOS)
        
        # SDå¤„ç†
        print("ğŸ”„ Running Diffusion...")
        
        result = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=input_img,
            strength=strength,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps
        ).images[0]
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜å¤„ç†åçš„PNG
        png_path = output_path / f"sd_enhanced_{timestamp}.png"
        result.save(png_path)
        print(f"âœ… PNG saved: {png_path}")
        
        # çŸ¢é‡åŒ–
        print("\nğŸ”„ Vectorizing...")
        svg_path = self.vectorize(result, output_path, timestamp)
        
        print(f"\nâœ… All done!")
        print(f"   PNG: {png_path}")
        print(f"   SVG: {svg_path}")
        
        # æ‰“å¼€ç»“æœ
        import subprocess
        subprocess.run(["open", str(png_path)])
        
        return png_path, svg_path
    
    def vectorize(self, img: Image.Image, output_path: Path, timestamp: str):
        """çŸ¢é‡åŒ–å›¾åƒ"""
        try:
            # ä½¿ç”¨å·²æœ‰çš„çŸ¢é‡åŒ–å™¨
            from sam3_color_vectorizer_fast import SAM3ColorVectorizerFast
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_path = output_path / f"temp_{timestamp}.png"
            img.save(temp_path)
            
            # çŸ¢é‡åŒ–
            vectorizer = SAM3ColorVectorizerFast(n_workers=8)
            result = vectorizer.vectorize(str(temp_path))
            
            # è·å–SVGè·¯å¾„ï¼ˆè¿”å›å€¼å¯èƒ½æ˜¯dictæˆ–strï¼‰
            if isinstance(result, dict):
                svg_path = result.get('svg_path', result.get('path', ''))
            else:
                svg_path = str(result) if result else ''
            
            # ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•
            import shutil
            final_svg = output_path / f"vectorized_{timestamp}.svg"
            
            if svg_path and Path(svg_path).exists():
                shutil.copy(svg_path, final_svg)
                print(f"âœ… SVG saved: {final_svg}")
            else:
                # æ‰¾æœ€æ–°ç”Ÿæˆçš„svg
                svg_dir = Path("/Volumes/Seagate/SAM3/12_è¯­ä¹‰çŸ¢é‡åŒ–/02_è¾“å‡ºç»“æœ/sam3_color_svg")
                svgs = list(svg_dir.glob("*.svg"))
                if svgs:
                    latest = max(svgs, key=lambda p: p.stat().st_mtime)
                    shutil.copy(latest, final_svg)
                    print(f"âœ… SVG saved: {final_svg}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_path.unlink(missing_ok=True)
            
            return final_svg
            
        except Exception as e:
            print(f"   âš ï¸ Vectorization failed: {e}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    
    # æ£€æŸ¥è®¾å¤‡
    device = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Device: {device}")
    
    # åˆ›å»ºå¢å¼ºå™¨
    enhancer = SVGDiffusionEnhancer(device=device)
    
    # åŠ è½½SDï¼ˆé€‰æ‹©sd15æˆ–sdxlï¼‰
    enhancer.load_sd(model_type="sd15")  # sd15æ›´å¿«ï¼Œsdxlæ›´å¥½
    
    # å¤„ç†å›¾åƒ
    # å¯ä»¥è¾“å…¥SVGæˆ–æ™®é€šå›¾ç‰‡
    input_path = "/Volumes/Seagate/SAM3/12_è¯­ä¹‰çŸ¢é‡åŒ–/02_è¾“å‡ºç»“æœ/sam3_color_svg/sam3_color_vector.svg"
    
    # ä¸åŒçš„å¤„ç†æ•ˆæœç¤ºä¾‹ï¼š
    
    # 1. è‰ºæœ¯é£æ ¼åŒ–
    # prompt = "oil painting style, artistic, vibrant colors"
    
    # 2. å†™å®å¢å¼º
    # prompt = "photorealistic, detailed, high quality, 4k"
    
    # 3. å¡é€šé£æ ¼
    # prompt = "cartoon style, flat colors, vector art, simple shapes"
    
    # 4. ä¿æŒåŸæ ·ä½†å¢å¼ºç»†èŠ‚
    prompt = "enhanced details, high quality, sharp, professional"
    
    enhancer.process(
        input_path=input_path,
        prompt=prompt,
        strength=0.4,  # 0.3-0.5 ä¿ç•™åŸå›¾è¾ƒå¤šï¼Œ0.6-0.8 å˜åŒ–è¾ƒå¤§
        guidance_scale=7.5,
        num_inference_steps=30,
        output_dir="/Volumes/Seagate/SAM3/13_SVG_Diffusion/output_enhanced"
    )


if __name__ == "__main__":
    main()
