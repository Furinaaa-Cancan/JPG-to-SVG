#!/usr/bin/env python3
"""
SAM3æé™åˆ†å‰²ç³»ç»Ÿ
- MPS GPUåŠ é€Ÿ
- è‡ªåŠ¨maskç”Ÿæˆ
- å¤šå°ºåº¦å¤„ç†
- ç¨³å®šæ€§è¯„åˆ†
- æœ€å¤§ç»†èŠ‚æå–
"""

import sys
import cv2
import numpy as np
from PIL import Image
from pathlib import Path
import json
import time
import torch
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

# æ·»åŠ SAM3è·¯å¾„
sys.path.insert(0, "/Volumes/Seagate/SAM3/æ¨¡å‹åº“/01_SAM3æ ¸å¿ƒæ¨¡å‹")

from sam3.model_builder import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor


class SAM3Ultimate:
    """SAM3æé™åˆ†å‰²å™¨"""
    
    def __init__(self, use_mps: bool = True, num_workers: int = 12):
        print("\nğŸš€ Initializing SAM3 Ultimate...")
        
        # é€‰æ‹©è®¾å¤‡
        if use_mps and torch.backends.mps.is_available():
            self.device = "mps"
            print("   Using MPS (Metal Performance Shaders) acceleration âš¡")
        elif torch.cuda.is_available():
            self.device = "cuda"
            print("   Using CUDA acceleration âš¡")
        else:
            self.device = "cpu"
            print("   Using CPU (will be slower)")
        
        self.num_workers = num_workers
        print(f"   CPU workers: {num_workers}")
        
        # åŠ è½½SAM3æ¨¡å‹
        try:
            self.model = build_sam3_image_model(device=self.device)
            self.processor = Sam3Processor(self.model, device=self.device)
            print("âœ… SAM3 loaded successfully!")
        except Exception as e:
            print(f"âš ï¸  MPS failed, falling back to CPU: {e}")
            self.device = "cpu"
            self.model = build_sam3_image_model(device="cpu")
            self.processor = Sam3Processor(self.model, device="cpu")
            print("âœ… SAM3 loaded on CPU")
    
    def segment_everything_ultimate(self, image_path: str, output_dir: str = "02_è¾“å‡ºç»“æœ/sam3_ultimate"):
        """ä½¿ç”¨SAM3çš„æ‰€æœ‰é«˜çº§åŠŸèƒ½è¿›è¡Œæé™åˆ†å‰²"""
        
        print("\n" + "="*70)
        print("ğŸ’ SAM3 ULTIMATE SEGMENTATION - MAXIMUM POWER")
        print("="*70)
        
        start_time = time.time()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½å›¾åƒ
        img = Image.open(image_path)
        img_array = np.array(img)
        h, w = img_array.shape[:2]
        
        print(f"\nğŸ“· Input: {image_path}")
        print(f"   Size: {w}x{h}")
        print(f"   Device: {self.device}")
        
        # Step 1: è®¾ç½®å›¾åƒ
        print("\nğŸ”§ Step 1: Setting image in SAM3")
        state = self.processor.set_image(img)
        
        # Step 2: ä½¿ç”¨SAM3çš„è‡ªåŠ¨maskç”ŸæˆåŠŸèƒ½
        print("\nğŸ¯ Step 2: Automatic Mask Generation")
        auto_masks = self.automatic_mask_generation(state, img_array)
        print(f"   Generated {len(auto_masks)} automatic masks")
        
        # Step 3: è¶…è¯¦ç»†æ–‡æœ¬æç¤º - å¹¶è¡Œå¤„ç†
        print("\nğŸ“ Step 3: Parallel Text Prompting")
        text_masks = self.parallel_text_prompting(state, img_array)
        print(f"   Generated {len(text_masks)} text-prompted masks")
        
        # Step 4: å¤šå°ºåº¦å¤„ç†
        print("\nğŸ”¬ Step 4: Multi-scale Processing")
        scale_masks = self.multiscale_processing(img, img_array)
        print(f"   Generated {len(scale_masks)} multi-scale masks")
        
        # Step 5: ç¨³å®šæ€§è¯„åˆ†è¿‡æ»¤
        print("\nâ­ Step 5: Stability Score Filtering")
        all_masks = auto_masks + text_masks + scale_masks
        filtered_masks = self.filter_by_stability(all_masks)
        print(f"   Filtered to {len(filtered_masks)} high-quality masks")
        
        # Step 6: æ™ºèƒ½å»é‡
        print("\nğŸ”„ Step 6: Intelligent Deduplication")
        unique_masks = self.smart_deduplication(filtered_masks)
        print(f"   Final unique masks: {len(unique_masks)}")
        
        # Step 7: ç”Ÿæˆå¯è§†åŒ–
        print("\nğŸ¨ Step 7: Generating Visualizations")
        self.save_all_visualizations(img_array, unique_masks, output_path)
        
        # Step 8: ç”ŸæˆæŠ¥å‘Š
        stats = self.generate_ultimate_report(unique_masks, output_path)
        
        process_time = time.time() - start_time
        
        print(f"\n" + "="*70)
        print(f"âœ… ULTIMATE SEGMENTATION COMPLETE!")
        print(f"   Total masks: {len(unique_masks)}")
        print(f"   Processing time: {process_time:.1f}s")
        print(f"   Speed: {len(unique_masks)/process_time:.1f} masks/sec")
        print(f"   Device: {self.device}")
        print("="*70)
        
        # è‡ªåŠ¨æ‰“å¼€å±•ç¤º
        import subprocess
        subprocess.run(["open", str(output_path / "ultimate_showcase.html")])
        
        return {
            'masks': unique_masks,
            'stats': stats,
            'time': process_time
        }
    
    def automatic_mask_generation(self, state, img_array: np.ndarray) -> list:
        """ä½¿ç”¨SAM3çš„è‡ªåŠ¨maskç”ŸæˆåŠŸèƒ½"""
        
        masks = []
        h, w = img_array.shape[:2]
        
        # ä½¿ç”¨ä¸åŒçš„ç½‘æ ¼å¯†åº¦
        grid_sizes = [16, 32, 48]  # å¤šç§ç½‘æ ¼å¯†åº¦
        
        for grid_size in grid_sizes:
            print(f"   Grid {grid_size}x{grid_size}...")
            
            x_step = w // grid_size
            y_step = h // grid_size
            
            # æ‰¹é‡é‡‡æ ·ç‚¹
            sample_points = []
            for i in range(grid_size):
                for j in range(grid_size):
                    x = i * x_step + x_step // 2
                    y = j * y_step + y_step // 2
                    sample_points.append((x, y))
            
            # æ¯æ¬¡å¤„ç†ä¸€æ‰¹ç‚¹
            batch_size = 50
            for batch_idx in range(0, len(sample_points), batch_size):
                batch = sample_points[batch_idx:batch_idx + batch_size]
                
                for x, y in batch:
                    try:
                        prompt_state = self.processor.set_text_prompt(f"object at {x},{y}", state)
                        
                        if prompt_state and 'masks' in prompt_state:
                            mask_data = prompt_state['masks']
                            if mask_data is not None and hasattr(mask_data, 'shape'):
                                if mask_data.shape[0] > 0:
                                    mask = mask_data[0] if len(mask_data.shape) > 2 else mask_data
                                    
                                    if hasattr(mask, 'cpu'):
                                        mask = mask.cpu().numpy()
                                    
                                    masks.append({
                                        'mask': mask,
                                        'point': (x, y),
                                        'grid': grid_size,
                                        'score': 1.0
                                    })
                    except:
                        continue
        
        return masks
    
    def parallel_text_prompting(self, state, img_array: np.ndarray) -> list:
        """å¹¶è¡Œæ–‡æœ¬æç¤ºå¤„ç†"""
        
        # è¶…è¯¦ç»†çš„æç¤ºè¯
        prompts = self.get_comprehensive_prompts()
        
        # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
        masks = []
        
        def process_prompt(prompt):
            try:
                prompt_state = self.processor.set_text_prompt(prompt, state)
                
                if prompt_state and 'masks' in prompt_state:
                    mask_data = prompt_state['masks']
                    if mask_data is not None and hasattr(mask_data, 'shape'):
                        if mask_data.shape[0] > 0:
                            mask = mask_data[0] if len(mask_data.shape) > 2 else mask_data
                            
                            if hasattr(mask, 'cpu'):
                                mask = mask.cpu().numpy()
                            
                            return {
                                'mask': mask,
                                'prompt': prompt,
                                'score': 1.0
                            }
            except:
                pass
            return None
        
        # å¹¶è¡Œå¤„ç†ï¼ˆæ–‡æœ¬æç¤ºå¯ä»¥å¹¶è¡Œï¼‰
        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            results = list(executor.map(process_prompt, prompts))
        
        masks = [r for r in results if r is not None]
        
        print(f"   Parallel processing: {len(masks)}/{len(prompts)} successful")
        
        return masks
    
    def get_comprehensive_prompts(self) -> list:
        """è·å–è¶…å…¨é¢çš„æç¤ºè¯åˆ—è¡¨"""
        
        return [
            # æœè£…è£…é¥° - è¶…è¯¦ç»†
            "gold embroidery", "golden thread", "gold metallic trim",
            "embroidered pattern", "decorative embroidery",
            "sequins", "sparkles", "glitter", "shiny decorations",
            "beads", "pearl beads", "jewelry beads",
            "lace trim", "lace pattern", "delicate lace",
            "ribbon detail", "bow decoration", "tassel",
            "button", "decorative button", "metallic button",
            "zipper", "buckle", "clasp", "fastener",
            "belt detail", "waist decoration",
            
            # æœè£…ç»“æ„ - æè¯¦ç»†
            "blue velvet dress", "royal blue costume", "cobalt blue fabric",
            "dress bodice", "corset", "chest piece",
            "sleeve detail", "puffed sleeve", "shoulder detail",
            "collar decoration", "neckline", "neck trim",
            "skirt fold", "dress hem", "bottom trim",
            "fabric wrinkle", "cloth crease", "fold line",
            "shadow on dress", "highlight on fabric",
            "dress texture", "velvet texture", "fabric weave",
            
            # äººç‰©ç»†èŠ‚ - æœ€è¯¦ç»†
            "face", "facial skin", "facial features",
            "blonde wavy hair", "curly hair", "hair strand",
            "eye", "eyelash", "eyebrow", "eyelid",
            "nose", "nostril", "nose bridge",
            "mouth", "lips", "red lipstick", "teeth",
            "chin", "jaw", "cheek", "cheekbone",
            "forehead", "temple",
            "ear", "earring",
            "neck", "throat", "collarbone",
            "hand", "palm", "finger", "fingernail",
            "wrist", "arm", "elbow", "shoulder",
            "skin", "skin tone", "skin texture",
            
            # éª·é«…é“å…· - å®Œæ•´åˆ†å‰²
            "skeleton", "full skeleton", "complete skeleton",
            "skull", "skull head", "skull face", "skull teeth",
            "rib cage", "ribs", "rib bones",
            "spine", "vertebrae", "backbone",
            "arm bones", "leg bones", "hand bones",
            "bone", "white bone", "skeletal bone",
            "bone joint", "bone connection",
            "skeleton prop", "prop skeleton", "stage prop",
            
            # èƒŒæ™¯å…ƒç´ 
            "background", "blue background", "gradient background",
            "stage background", "backdrop",
            "light", "lighting", "spotlight", "stage light",
            "smoke", "fog", "mist", "haze effect",
            "shadow area", "dark region",
            
            # é¢œè‰²åŒºåŸŸ - ç²¾ç¡®
            "white region", "bright white area",
            "black region", "dark black area",
            "blue region", "deep blue area",
            "gold region", "golden area",
            "red region", "pink area",
            
            # ç‰¹æ®Šæ•ˆæœ
            "reflection", "shiny surface", "glossy area",
            "matte surface", "texture detail",
            "edge", "boundary", "outline", "contour",
            "transition area", "gradient transition"
        ]
    
    def multiscale_processing(self, img: Image.Image, img_array: np.ndarray) -> list:
        """å¤šå°ºåº¦å¤„ç† - ä¸åŒåˆ†è¾¨ç‡æ•æ‰ä¸åŒç»†èŠ‚"""
        
        masks = []
        scales = [0.5, 0.75, 1.0, 1.25]  # å¤šä¸ªç¼©æ”¾çº§åˆ«
        
        for scale in scales:
            if scale == 1.0:
                continue  # åŸå§‹å°ºå¯¸å·²ç»å¤„ç†è¿‡äº†
            
            print(f"   Processing at {scale}x scale...")
            
            # ç¼©æ”¾å›¾åƒ
            new_w = int(img.width * scale)
            new_h = int(img.height * scale)
            scaled_img = img.resize((new_w, new_h), Image.LANCZOS)
            
            # å¤„ç†ç¼©æ”¾åçš„å›¾åƒ
            try:
                state = self.processor.set_image(scaled_img)
                
                # åœ¨ç¼©æ”¾å›¾åƒä¸Šè¿›è¡Œé‡‡æ ·
                grid_size = 24
                x_step = new_w // grid_size
                y_step = new_h // grid_size
                
                for i in range(0, grid_size, 3):  # ç¨€ç–é‡‡æ ·
                    for j in range(0, grid_size, 3):
                        x = i * x_step + x_step // 2
                        y = j * y_step + y_step // 2
                        
                        try:
                            prompt_state = self.processor.set_text_prompt(f"region at {x},{y}", state)
                            
                            if prompt_state and 'masks' in prompt_state:
                                mask_data = prompt_state['masks']
                                if mask_data is not None and hasattr(mask_data, 'shape'):
                                    if mask_data.shape[0] > 0:
                                        mask = mask_data[0] if len(mask_data.shape) > 2 else mask_data
                                        
                                        if hasattr(mask, 'cpu'):
                                            mask = mask.cpu().numpy()
                                        
                                        # ç¼©æ”¾å›åŸå§‹å¤§å°
                                        mask_resized = cv2.resize(
                                            mask.astype(np.float32),
                                            (img.width, img.height),
                                            interpolation=cv2.INTER_LINEAR
                                        )
                                        
                                        masks.append({
                                            'mask': mask_resized,
                                            'scale': scale,
                                            'score': 1.0
                                        })
                        except:
                            continue
            except:
                continue
        
        return masks
    
    def filter_by_stability(self, masks: list) -> list:
        """æ ¹æ®ç¨³å®šæ€§è¯„åˆ†è¿‡æ»¤mask"""
        
        filtered = []
        
        for mask_data in masks:
            mask = mask_data['mask']
            
            # è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
            if len(mask.shape) > 2:
                mask = mask.squeeze()
            
            # 1. é¢ç§¯ä¸èƒ½å¤ªå°
            area = np.sum(mask > 0.5)
            if area < 100:
                continue
            
            # 2. è®¡ç®—ç´§å‡‘åº¦
            if area > 0:
                perimeter = self.calculate_perimeter(mask > 0.5)
                compactness = 4 * np.pi * area / (perimeter * perimeter) if perimeter > 0 else 0
                
                # è¿‡æ»¤å¤ªåˆ†æ•£çš„mask
                if compactness < 0.01:
                    continue
            
            # 3. è®¡ç®—å¡«å……åº¦
            bbox = self.get_bbox(mask > 0.5)
            if bbox:
                x1, y1, x2, y2 = bbox
                bbox_area = (x2 - x1) * (y2 - y1)
                fill_ratio = area / bbox_area if bbox_area > 0 else 0
                
                # è¿‡æ»¤å¡«å……åº¦å¤ªä½çš„
                if fill_ratio < 0.2:
                    continue
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            score = compactness * 0.5 + fill_ratio * 0.5
            mask_data['stability_score'] = score
            
            filtered.append(mask_data)
        
        # æŒ‰è¯„åˆ†æ’åº
        filtered.sort(key=lambda x: x.get('stability_score', 0), reverse=True)
        
        return filtered
    
    def calculate_perimeter(self, binary_mask: np.ndarray) -> float:
        """è®¡ç®—maskå‘¨é•¿"""
        contours, _ = cv2.findContours(
            binary_mask.astype(np.uint8),
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )
        if contours:
            return cv2.arcLength(contours[0], True)
        return 0
    
    def get_bbox(self, binary_mask: np.ndarray) -> tuple:
        """è·å–bounding box"""
        coords = np.argwhere(binary_mask)
        if len(coords) > 0:
            y1, x1 = coords.min(axis=0)
            y2, x2 = coords.max(axis=0)
            return (x1, y1, x2, y2)
        return None
    
    def smart_deduplication(self, masks: list) -> list:
        """æ™ºèƒ½å»é‡ - è€ƒè™‘å¤šç§å› ç´ """
        
        if not masks:
            return []
        
        # æŒ‰ç¨³å®šæ€§è¯„åˆ†æ’åº
        masks.sort(key=lambda x: x.get('stability_score', 0), reverse=True)
        
        unique_masks = []
        
        for mask_data in masks:
            mask = mask_data['mask']
            
            if len(mask.shape) > 2:
                mask = mask.squeeze()
            
            # æ£€æŸ¥ä¸å·²æœ‰maskçš„é‡å 
            is_duplicate = False
            
            for unique in unique_masks:
                unique_mask = unique['mask']
                if len(unique_mask.shape) > 2:
                    unique_mask = unique_mask.squeeze()
                
                # ç¡®ä¿å°ºå¯¸åŒ¹é…
                if mask.shape != unique_mask.shape:
                    unique_mask = cv2.resize(unique_mask, (mask.shape[1], mask.shape[0]))
                
                # è®¡ç®—IOU
                intersection = np.logical_and(mask > 0.5, unique_mask > 0.5).sum()
                union = np.logical_or(mask > 0.5, unique_mask > 0.5).sum()
                
                if union > 0:
                    iou = intersection / union
                    if iou > 0.8:  # 80%é‡å 
                        is_duplicate = True
                        break
            
            if not is_duplicate:
                unique_masks.append(mask_data)
                
                # é™åˆ¶æœ€å¤§æ•°é‡
                if len(unique_masks) >= 200:
                    break
        
        return unique_masks
    
    def save_all_visualizations(self, img: np.ndarray, masks: list, output_path: Path):
        """ä¿å­˜æ‰€æœ‰å¯è§†åŒ–"""
        
        # ä¿å­˜å•ç‹¬çš„masks
        masks_dir = output_path / "masks"
        masks_dir.mkdir(exist_ok=True)
        
        for i, mask_data in enumerate(masks[:100]):
            mask = mask_data['mask']
            if len(mask.shape) > 2:
                mask = mask.squeeze()
            
            binary_mask = (mask > 0.5).astype(np.uint8) * 255
            
            # ç”Ÿæˆæè¿°æ€§æ–‡ä»¶å
            score = mask_data.get('stability_score', 0)
            prompt = mask_data.get('prompt', f'auto_{i}')[:30].replace(' ', '_')
            
            filename = f"{i:03d}_{prompt}_score{score:.2f}.png"
            Image.fromarray(binary_mask).save(masks_dir / filename)
        
        # åˆ›å»ºå½©è‰²ç»„åˆ
        composite = self.create_colorful_composite(img, masks)
        Image.fromarray(composite).save(output_path / "ultimate_composite.png")
        
        # åˆ›å»ºè¾¹ç¼˜å›¾
        edges = self.create_detailed_edges(masks, img.shape[:2])
        Image.fromarray(edges).save(output_path / "ultimate_edges.png")
        
        print(f"   Saved visualizations to {output_path}")
    
    def create_colorful_composite(self, img: np.ndarray, masks: list) -> np.ndarray:
        """åˆ›å»ºå½©è‰²ç»„åˆ"""
        
        h, w = img.shape[:2]
        overlay = np.zeros((h, w, 3), dtype=np.float32)
        
        np.random.seed(42)
        colors = np.random.rand(len(masks), 3) * 255
        
        for i, mask_data in enumerate(masks):
            mask = mask_data['mask']
            if len(mask.shape) > 2:
                mask = mask.squeeze()
            
            if mask.shape != (h, w):
                mask = cv2.resize(mask, (w, h))
            
            binary_mask = (mask > 0.5)
            
            for c in range(3):
                overlay[:, :, c] += binary_mask * colors[i, c] * 0.3
        
        overlay = np.clip(overlay, 0, 255).astype(np.uint8)
        composite = cv2.addWeighted(img, 0.6, overlay, 0.4, 0)
        
        return composite
    
    def create_detailed_edges(self, masks: list, shape: tuple) -> np.ndarray:
        """åˆ›å»ºè¯¦ç»†è¾¹ç¼˜å›¾"""
        
        h, w = shape
        edges = np.zeros((h, w, 3), dtype=np.uint8)
        
        np.random.seed(42)
        colors = np.random.rand(len(masks), 3) * 255
        
        for i, mask_data in enumerate(masks):
            mask = mask_data['mask']
            if len(mask.shape) > 2:
                mask = mask.squeeze()
            
            if mask.shape != (h, w):
                mask = cv2.resize(mask, (w, h))
            
            binary_mask = (mask > 0.5).astype(np.uint8)
            contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            color = colors[i].astype(int).tolist()
            cv2.drawContours(edges, contours, -1, color, 2)
        
        return edges
    
    def generate_ultimate_report(self, masks: list, output_path: Path) -> dict:
        """ç”Ÿæˆç»ˆææŠ¥å‘Š"""
        
        stats = {
            'total_masks': len(masks),
            'device': self.device,
            'workers': self.num_workers,
            'avg_stability': np.mean([m.get('stability_score', 0) for m in masks]),
            'generation_methods': {}
        }
        
        # ç»Ÿè®¡ç”Ÿæˆæ–¹æ³•
        for mask in masks:
            if 'prompt' in mask:
                method = 'text_prompt'
            elif 'grid' in mask:
                method = f'auto_grid_{mask["grid"]}'
            elif 'scale' in mask:
                method = f'multiscale_{mask["scale"]}'
            else:
                method = 'other'
            
            stats['generation_methods'][method] = stats['generation_methods'].get(method, 0) + 1
        
        # ä¿å­˜JSON
        with open(output_path / "ultimate_report.json", 'w') as f:
            json.dump(stats, f, indent=2)
        
        # åˆ›å»ºHTMLå±•ç¤º
        self.create_ultimate_html(output_path, stats)
        
        return stats
    
    def create_ultimate_html(self, output_path: Path, stats: dict):
        """åˆ›å»ºç»ˆæHTMLå±•ç¤º"""
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>SAM3 Ultimate Segmentation</title>
            <meta charset="utf-8">
            <style>
                body {{
                    margin: 0;
                    font-family: -apple-system, sans-serif;
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white;
                }}
                .header {{
                    text-align: center;
                    padding: 60px 20px;
                    background: rgba(0,0,0,0.3);
                }}
                h1 {{
                    font-size: 4em;
                    margin: 0;
                    text-shadow: 0 0 20px rgba(255,255,255,0.5);
                }}
                .subtitle {{
                    font-size: 1.5em;
                    margin-top: 10px;
                }}
                .container {{
                    max-width: 1600px;
                    margin: 40px auto;
                    padding: 0 20px;
                }}
                .stats {{
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                    gap: 20px;
                    margin-bottom: 40px;
                }}
                .stat-card {{
                    background: rgba(255,255,255,0.1);
                    backdrop-filter: blur(10px);
                    border-radius: 20px;
                    padding: 30px;
                    text-align: center;
                }}
                .stat-number {{
                    font-size: 3em;
                    font-weight: bold;
                    color: #FFD700;
                }}
                .stat-label {{
                    margin-top: 10px;
                    text-transform: uppercase;
                    letter-spacing: 2px;
                }}
                .images {{
                    display: grid;
                    grid-template-columns: 1fr 1fr;
                    gap: 30px;
                }}
                .image-card {{
                    background: rgba(0,0,0,0.3);
                    border-radius: 20px;
                    overflow: hidden;
                }}
                .image-header {{
                    padding: 20px;
                    font-size: 1.3em;
                    font-weight: bold;
                }}
                img {{
                    width: 100%;
                    display: block;
                }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>âš¡ SAM3 ULTIMATE</h1>
                <div class="subtitle">Maximum Power Segmentation</div>
            </div>
            
            <div class="container">
                <div class="stats">
                    <div class="stat-card">
                        <div class="stat-number">{stats['total_masks']}</div>
                        <div class="stat-label">Total Masks</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{stats['device'].upper()}</div>
                        <div class="stat-label">Device</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{stats['workers']}</div>
                        <div class="stat-label">CPU Workers</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{stats['avg_stability']:.2f}</div>
                        <div class="stat-label">Avg Stability</div>
                    </div>
                </div>
                
                <div class="images">
                    <div class="image-card">
                        <div class="image-header">ğŸ¨ Ultimate Composite</div>
                        <img src="ultimate_composite.png" alt="Composite">
                    </div>
                    <div class="image-card">
                        <div class="image-header">ğŸ“ Ultimate Edges</div>
                        <img src="ultimate_edges.png" alt="Edges">
                    </div>
                </div>
            </div>
        </body>
        </html>
        """
        
        with open(output_path / "ultimate_showcase.html", 'w') as f:
            f.write(html_content)


def main():
    """è¿è¡ŒSAM3æé™åˆ†å‰²"""
    
    # ä½¿ç”¨MPSåŠ é€Ÿå’Œ12æ ¸CPU
    segmenter = SAM3Ultimate(use_mps=True, num_workers=12)
    
    result = segmenter.segment_everything_ultimate("01_è¾“å…¥å›¾ç‰‡/Ladygaga_2.jpg")
    
    return result


if __name__ == "__main__":
    main()
